{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e7e2c13d-e099-4861-999c-13d2d8da51a7",
   "metadata": {},
   "source": [
    "## Clean up and impute missing projected (2010-2100) GDPpc, GDP, and population values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78887ae8-c469-4248-b886-cae2f9a231a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a58ff364-b6bd-431a-b4d6-c7b11d471e51",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import warnings\n",
    "from itertools import product as lstprod\n",
    "from pathlib import Path\n",
    "\n",
    "import dask.dataframe as ddf\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "import xarray as xr\n",
    "from dask_gateway import Gateway\n",
    "from scipy.optimize import minimize as opt_min\n",
    "from shapely.geometry import MultiPolygon, Point, Polygon\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from sliiders.spatial import iso_poly_box_getter\n",
    "from sliiders import country_level_ypk as ypk_fn\n",
    "from sliiders import settings as sset\n",
    "\n",
    "# dask gateway setup\n",
    "gateway = Gateway()\n",
    "cluster_name = sset.DASK_IMAGE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb1ad6d9-3e1e-4930-8d64-2335bf037e36",
   "metadata": {},
   "source": [
    "## Importing and cleaning SSP-IAM projections\n",
    "\n",
    "### Raw data re-formatting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c2cd5c54-8cbd-41ee-a59f-8814a08c869b",
   "metadata": {},
   "outputs": [],
   "source": [
    "iiasa_raw_df = pd.read_csv(sset.DIR_YPK_RAW / \"SspDb_country_data_2013-06-12.csv\")\n",
    "iiasa_pop = iiasa_raw_df.loc[iiasa_raw_df.VARIABLE == \"Population\", :].sort_values(\n",
    "    [\"SCENARIO\", \"MODEL\", \"REGION\"]\n",
    ")\n",
    "iiasa_gdp = iiasa_raw_df.loc[iiasa_raw_df.VARIABLE == \"GDP|PPP\", :].sort_values(\n",
    "    [\"SCENARIO\", \"MODEL\", \"REGION\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b50f5c7-da7c-49d9-a56d-6d80ebaad799",
   "metadata": {},
   "source": [
    "### Population\n",
    "\n",
    "We will only take IIASA projections, with the exception of countries whose information are in OECD projections but not in IIASA.\n",
    "\n",
    "#### Basic cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f9257a09-1d0b-4823-97e9-b4128047697f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaning the projections\n",
    "ii_pop_clean = ypk_fn.ssp_and_model_simplify(\"SCENARIO\", \"MODEL\", iiasa_pop)\n",
    "ii_pop_clean.sort_values([\"ccode\", \"ssp\", \"iam\"], inplace=True)\n",
    "\n",
    "# double-checking if IIASA and IIASA-WiC values are same\n",
    "v_ = [str(y) for y in np.arange(2010, 2105, 5)]\n",
    "for i in set(ii_pop_clean.ccode):\n",
    "    row = ii_pop_clean[ii_pop_clean.ccode == i]\n",
    "    iams = set(row.iam)\n",
    "    if (\"IIASA\" in iams) and (\"IIASA-WiC\" in iams):\n",
    "        w1 = row.loc[row.iam == \"IIASA\", v_].values\n",
    "        w2 = row.loc[row.iam == \"IIASA-WiC\", v_].values\n",
    "        if not (w1 == w2).all():\n",
    "            print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d27b24a5-9e62-4cbe-8e44-18cc91f4d7bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cleaning up by gathering only two population IAMs per country:\n",
    "# IIASA (or equivalently, IIASA-WiC), and OECD\n",
    "ii_pop = pd.DataFrame(ii_pop_clean[[\"ccode\", \"ssp\", \"iam\"] + v_])\n",
    "new_v_ = [\"v_\" + str(y) for y in v_]\n",
    "\n",
    "for i, ccode in enumerate(list(set(ii_pop_clean.ccode))):\n",
    "    j = 0\n",
    "    indiv_df = []\n",
    "    case = ii_pop[ii_pop.ccode == ccode]\n",
    "    get_these = []\n",
    "    ## add oecd if existing\n",
    "    if \"OECD\" in set(case.iam):\n",
    "        indiv_df.append(case[case.iam == \"OECD\"].values)\n",
    "        j += 1\n",
    "    ## add only one of IIASA OR IIASA-WiC\n",
    "    if \"IIASA\" in set(case.iam):\n",
    "        indiv_df.append(case[case.iam == \"IIASA\"].values)\n",
    "        j += 1\n",
    "    elif \"IIASA-WiC\" in set(case.iam):\n",
    "        indiv_df.append(case[case.iam == \"IIASA-WiC\"].values)\n",
    "        j += 1\n",
    "\n",
    "    indiv_df = pd.DataFrame(\n",
    "        np.vstack(indiv_df), columns=[\"ccode\", \"ssp\", \"iam\"] + new_v_\n",
    "    )\n",
    "    indiv_df[\"howmany_iam\"] = j\n",
    "    if i == 0:\n",
    "        agg_df = indiv_df.copy()\n",
    "    else:\n",
    "        agg_df = pd.concat([agg_df, indiv_df], axis=0)\n",
    "\n",
    "agg_df[\"unit\"] = \"millions\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "114700b0-8bb1-401f-9ad6-f15f6d6f7584",
   "metadata": {},
   "outputs": [],
   "source": [
    "# brief clean-ups\n",
    "ii_pop = agg_df.copy()\n",
    "ii_pop[\"iam_fill\"] = \"-\"\n",
    "ii_pop.loc[ii_pop.iam == \"IIASA-WiC\", \"iam\"] = \"IIASA\"\n",
    "\n",
    "# adding the extra rows for missing iams\n",
    "for i, ccode in enumerate(set(ii_pop.ccode)):\n",
    "    case = ii_pop[ii_pop.ccode == ccode]\n",
    "    if case[\"howmany_iam\"][0] == 1:\n",
    "        copy_case = pd.DataFrame(case)\n",
    "        if set([\"OECD\"]) == set(copy_case.iam):\n",
    "            copy_case[\"iam\"], copy_case[\"iam_fill\"] = \"IIASA\", \"OECD\"\n",
    "        elif set([\"IIASA\"]) == set(copy_case.iam):\n",
    "            copy_case[\"iam\"], copy_case[\"iam_fill\"] = \"OECD\", \"IIASA\"\n",
    "        ii_pop = pd.concat([ii_pop, copy_case], axis=0)\n",
    "\n",
    "## further re-ordering cleanups\n",
    "ii_pop.sort_values([\"ccode\", \"ssp\", \"iam\"], inplace=True)\n",
    "ii_pop.set_index([\"ccode\", \"ssp\", \"iam\"], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c53c374b-7816-4c34-89d0-7273df29890f",
   "metadata": {},
   "source": [
    "#### Cleaning up for the case of France\n",
    "\n",
    "In the French case, IIASA's version has the 5 overseas departments (i.e., `MYT`, `MTQ`, `GUF`, `GLP`, and `REU`) **excluded** when it calculates the French populations. This is different in the OECD's version of the French population since it seems to **include** the said overseas departments. This can be confirmed below as the values for the sum of IIASA's populations for `MYT`, `MTQ`, `GUF`, `GLP`, `REU` and `FRA` is approximately the same as the values for OECD's French population.\n",
    "\n",
    "From here on, the French case for both IIASA and OECD will **exclude** the five overseas departments and keep them separately logged."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b549fa6b-6943-4dba-ac0d-c101934f5e75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SSP1: 0.0\n",
      "SSP2: 0.0\n",
      "SSP3: 0.0\n",
      "SSP4: 0.0\n",
      "SSP5: 0.0\n"
     ]
    }
   ],
   "source": [
    "## checking\n",
    "fra_dept = [\"FRA\", \"MYT\", \"MTQ\", \"GUF\", \"GLP\", \"REU\"]\n",
    "v_fut_5 = [x for x in ii_pop.columns if \"v_\" in x]\n",
    "for ssp in [\"SSP{}\".format(i) for i in range(1, 6)]:\n",
    "    ## OECD case\n",
    "    oecd_val = ii_pop.loc[(\"FRA\", ssp, \"OECD\"), v_fut_5].values\n",
    "\n",
    "    ## IIASA case\n",
    "    iiasa_val = ii_pop.loc[(fra_dept, ssp, \"IIASA\"), v_fut_5].values\n",
    "    iiasa_val = np.sum(iiasa_val, axis=0)\n",
    "\n",
    "    jointhese = [ssp, str(round(np.sum((oecd_val - iiasa_val) ** 2), 4))]\n",
    "    print(\": \".join(jointhese))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74d78baf-cc04-4381-8621-853747e0e3ce",
   "metadata": {},
   "source": [
    "The above confirms that OECD cases do include all of the five overseas departments when calculating their population. So we will subtract these values to get the \"mainland France\" population values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "00eebffc-9e8d-4c4c-ae6c-7edb7608a0bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "ii_pop_fra = ii_pop.copy()\n",
    "csi = [\"ccode\", \"ssp\", \"iam\"]\n",
    "for ssp in [\"SSP{}\".format(i) for i in range(1, 6)]:\n",
    "    fra_dept_oecd = ii_pop.loc[(fra_dept[1:], ssp, \"OECD\"), v_fut_5].values\n",
    "    fra_dept_oecd = np.sum(fra_dept_oecd, axis=0)\n",
    "    fra_overall_oecd = ii_pop.loc[(\"FRA\", ssp, \"OECD\"), v_fut_5].values\n",
    "\n",
    "    ii_pop_fra.loc[(\"FRA\", ssp, \"OECD\"), v_fut_5] = fra_overall_oecd - fra_dept_oecd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4908335d-5d31-4781-bb4e-99fd0ef2c556",
   "metadata": {},
   "source": [
    "#### Interpolating, turning into a long-panel format, and taking only the IIASA cases\n",
    "\n",
    "Projections are given every five years, so we will use interpolation to fill in the missing years' information. We will assume that the between any known adjacent two years' values (e.g., 2015 and 2020), the values grow log-linearly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0b4ffab9-6a77-46e8-8b5c-047aea3d4d51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# interpolate log-linearly and turning into a long-panel format\n",
    "ii_pop = ypk_fn.organize_hor_to_ver(\n",
    "    ypk_fn.log_lin_interpolate(ii_pop_fra),\n",
    "    \"ccode\",\n",
    "    [\"ssp\", \"iam\"],\n",
    "    \"pop\",\n",
    "    yrs=list(range(2010, 2101)),\n",
    ")\n",
    "\n",
    "# selecting only the IIASA cases\n",
    "ii_pop = (\n",
    "    ii_pop.loc[(slice(None), slice(None), slice(None), \"IIASA\"), :]\n",
    "    .reset_index()\n",
    "    .drop([\"howmany_iam\", \"iam_fill\", \"iam\"], axis=1)\n",
    "    .set_index([\"ccode\", \"year\", \"ssp\"])\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3d4cf18-324d-4c78-94f4-20512d98760d",
   "metadata": {},
   "source": [
    "#### Detecting those ISOs that are missing, and getting the country-level population estimates for these ISOs (from LandScan 2019)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d0dc5b3b-f4a3-44b3-b683-58384fab58f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f76c55d1c6fc4175a1d8c0547c25ce69",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<h2>GatewayCluster</h2>'), HBox(children=(HTML(value='\\n<div>\\n<style scoped>\\n    â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# cluster setup\n",
    "cluster = gateway.new_cluster(worker_image=cluster_name, profile=\"micro\")\n",
    "client = cluster.get_client()\n",
    "cluster.scale(20)\n",
    "cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4337c936-5fa5-475f-9d53-e0d264dfe710",
   "metadata": {},
   "outputs": [],
   "source": [
    "# detecting which ISOs are missing\n",
    "isos_pop_wproj = ii_pop.index.get_level_values(\"ccode\").unique()\n",
    "need_landscan = np.sort(np.setdiff1d(sset.ALL_ISOS, isos_pop_wproj))\n",
    "\n",
    "# landscan and (raw) coordinates\n",
    "ls19 = ddf.read_parquet(\n",
    "    sset.DIR_LANDSCAN_INT / \"population_with_xy.parquet\"\n",
    ").repartition(npartitions=20)\n",
    "ls19 = ls19.persist()\n",
    "\n",
    "# shapefiles requiring information from LandScan\n",
    "ctries_shp = gpd.read_parquet(sset.PATH_GADM_ADM1)\n",
    "\n",
    "# fixing ISO codes to be consistent with our convention\n",
    "ctries_shp.loc[ctries_shp.GID_0 == \"XKO\", \"GID_0\"] = \"KO-\"\n",
    "ctries_shp.loc[ctries_shp.GID_0 == \"XCL\", \"GID_0\"] = \"CL-\"\n",
    "\n",
    "# subsetting the shapefiles for those missing projections\n",
    "ctries_shp = ctries_shp.set_index([\"GID_0\"]).sort_index().loc[need_landscan]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aaa58cd-2c1c-4d55-aba6-eedf946234fe",
   "metadata": {},
   "source": [
    "Note that the current shapefile information we are using often has more than one MultiPolygon per ISO code, so we will create a shapefile dataset with one MultiPolygon per ISO code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "eb96648b-8e63-46e4-a7d3-455befe3987a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f05e715121847368cfbe6e5382fad72",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/56 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ctries_shp_lst = []\n",
    "for iso in tqdm(need_landscan):\n",
    "    iso_lst = []\n",
    "    for i in ctries_shp.loc[[iso], \"geometry\"].values:\n",
    "        if type(i) == MultiPolygon:\n",
    "            j = [x for x in i.geoms]\n",
    "        elif type(i) == Polygon:\n",
    "            j = [i]\n",
    "        iso_lst += j\n",
    "    ctries_shp_lst.append(MultiPolygon(iso_lst))\n",
    "\n",
    "ctries_shp_df = gpd.GeoDataFrame(\n",
    "    data={\"ccode\": need_landscan, \"geometry\": ctries_shp_lst}\n",
    ")\n",
    "ctries_shp_df.set_index([\"ccode\"], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a265451c-ca8f-452c-b91d-69778d85a9ec",
   "metadata": {},
   "source": [
    "Based on the ISO-relevant shapefiles and grid-level population in LandScan 2019, let us find the country-level population information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bb57e860-d8f5-48b5-ba02-13d353ed4762",
   "metadata": {},
   "outputs": [],
   "source": [
    "def subset_grid_find_pop(iso, shp_df=ctries_shp_df, ls_df=ls19):\n",
    "    poly_bounds = iso_poly_box_getter(iso, shp_df)\n",
    "    geom = shp_df.loc[iso, \"geometry\"]\n",
    "\n",
    "    sub_dfs = []\n",
    "    for bd in poly_bounds:\n",
    "        x_mn, x_mx, y_mn, y_mx = bd\n",
    "        sub_df = ls_df.loc[\n",
    "            (ls_df.x > x_mn) & (ls_df.y > y_mn) & (ls_df.x < x_mx) & (ls_df.y < y_mx), :\n",
    "        ].compute()\n",
    "        sub_dfs.append(sub_df)\n",
    "    sub_df = pd.concat(sub_dfs, axis=0).drop_duplicates([\"x_ix\", \"y_ix\"])\n",
    "\n",
    "    if sub_df.shape[0] == 0:\n",
    "        return 0\n",
    "\n",
    "    pop = 0\n",
    "    for l in range(sub_df.shape[0]):\n",
    "        pt = Point(sub_df.iloc[l, :][\"x\"], sub_df.iloc[l, :][\"y\"])\n",
    "        if geom.contains(pt):\n",
    "            pop += sub_df.iloc[l, :][\"population\"]\n",
    "\n",
    "    return pop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fe9156f-e11a-469d-a80e-0a8e0e7ecc7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this may take a while\n",
    "ls_msng_pop = []\n",
    "for iso in tqdm(need_landscan):\n",
    "    ls_msng_pop.append(subset_grid_find_pop(iso))\n",
    "\n",
    "msng_from_proj_pop = pd.DataFrame(data={\"pop\": ls_msng_pop, \"ccode\": need_landscan})\n",
    "msng_from_proj_pop.to_parquet(sset.DIR_YPK_INT / \"msng_from_iiasa_proj_pop.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3ae71c8f-da0a-4f28-b38e-3a81d155b817",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster.scale(0)\n",
    "cluster.close()\n",
    "client.close()\n",
    "cluster.shutdown()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d02ca449-e69b-4bf0-821b-8f2f770c8ef6",
   "metadata": {},
   "source": [
    "#### Attaching LandScan 2019 values to the overall population projections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6220182a-f73a-4cce-98b5-b861836ac806",
   "metadata": {},
   "outputs": [],
   "source": [
    "msng_from_proj_pop = pd.read_parquet(\n",
    "    sset.DIR_YPK_INT / \"msng_from_iiasa_proj_pop.parquet\"\n",
    ").set_index([\"ccode\"])\n",
    "\n",
    "pop_from_landscan = []\n",
    "for i in msng_from_proj_pop.index.get_level_values(\"ccode\"):\n",
    "    i_shell = ii_pop.loc[[\"USA\"], :].reset_index().copy()\n",
    "    i_shell[\"ccode\"] = i\n",
    "\n",
    "    ## adjusting it to millions of people\n",
    "    i_shell[\"pop\"] = msng_from_proj_pop.loc[i, \"pop\"] / 1000000\n",
    "    i_shell.set_index(ii_pop.index.names, inplace=True)\n",
    "    pop_from_landscan.append(i_shell)\n",
    "\n",
    "ii_pop = pd.concat([ii_pop] + pop_from_landscan, axis=0).sort_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a925ddf9-7704-4b1b-a3dc-51e499e137de",
   "metadata": {},
   "source": [
    "### GDPpc and GDP\n",
    "\n",
    "We will use IAMs `IIASA` and `OECD`.\n",
    "\n",
    "#### Basic cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "10751dae-3d6c-42a7-8862-862c7d91e072",
   "metadata": {},
   "outputs": [],
   "source": [
    "## cleaning the imported dataset\n",
    "csi = [\"ccode\", \"ssp\", \"iam\"]\n",
    "ii_gdp_clean = ypk_fn.ssp_and_model_simplify(\"SCENARIO\", \"MODEL\", iiasa_gdp)\n",
    "ii_gdp_clean.set_index(csi, inplace=True)\n",
    "ii_gdp_clean.sort_index(axis=0, inplace=True)\n",
    "\n",
    "num_v = [str(x) for x in np.arange(2010, 2105, 5)]\n",
    "v_name = [\"v_\" + str(v) for v in num_v]\n",
    "ii_gdp_clean.rename(columns=dict(zip(num_v, v_name)), inplace=True)\n",
    "ii_gdp_clean = ii_gdp_clean[v_name]\n",
    "\n",
    "## changing the values from billions of dollars to millions of dollars\n",
    "ii_gdp_clean[v_name] = ii_gdp_clean[v_name] * 1000\n",
    "\n",
    "## double-checking if IIASA and IIASA-WiC values are same\n",
    "## it's verifiable that IIASA and IIASA-WiC ones are the same\n",
    "for i in set(ii_gdp_clean.index.get_level_values(\"ccode\")):\n",
    "    row = ii_gdp_clean.loc[(i, slice(None), slice(None)), :]\n",
    "    iams = set(row.index.get_level_values(\"iam\"))\n",
    "    if (\"IIASA\" in iams) and (\"IIASA-WiC\" in iams):\n",
    "        w1 = row.loc[(slice(None), slice(None), \"IIASA\"), v_name].values\n",
    "        w2 = row.loc[(slice(None), slice(None), \"IIASA-WiC\"), v_name].values\n",
    "        if not (w1 == w2).all():\n",
    "            print(i)\n",
    "\n",
    "## getting only IIASA and OECD cases\n",
    "clean_ccodes = ii_gdp_clean.index.get_level_values(\"ccode\")\n",
    "for i, ccode in enumerate(list(set(clean_ccodes))):\n",
    "    j = 0\n",
    "    indiv_df = []\n",
    "    case = ii_gdp_clean.loc[(ccode, slice(None), slice(None)), :]\n",
    "    get_these = []\n",
    "    ## add oecd if existing\n",
    "    if \"OECD\" in set(case.index.get_level_values(\"iam\")):\n",
    "        indiv_df.append(case.loc[(slice(None), slice(None), \"OECD\"), :])\n",
    "        j += 1\n",
    "    ## add only one of IIASA OR IIASA-WiC\n",
    "    if \"IIASA\" in set(case.index.get_level_values(\"iam\")):\n",
    "        indiv_df.append(case.loc[(slice(None), slice(None), \"IIASA\"), :])\n",
    "        j += 1\n",
    "    elif \"IIASA-WiC\" in set(case.index.get_level_values(\"iam\")):\n",
    "        indiv_df.append(case.loc[(slice(None), slice(None), \"IIASA-WiC\"), :])\n",
    "        j += 1\n",
    "\n",
    "    indiv_df = pd.concat(indiv_df, axis=0)\n",
    "    indiv_df[\"howmany_iam\"] = j\n",
    "    if i == 0:\n",
    "        agg_df = indiv_df.copy()\n",
    "    else:\n",
    "        agg_df = pd.concat([agg_df, indiv_df], axis=0)\n",
    "\n",
    "ii_gdp = agg_df.copy().reset_index()\n",
    "ii_gdp[\"iam_fill\"] = \"-\"\n",
    "ii_gdp.loc[ii_gdp.iam == \"IIASA-WiC\", \"iam\"] = \"IIASA\"\n",
    "ii_gdp.set_index(csi, inplace=True)\n",
    "\n",
    "## If either OECD or IIASA track is missing, fill in using the other track\n",
    "for i, ccode in enumerate(set(ii_gdp.index.get_level_values(\"ccode\"))):\n",
    "    case = ii_gdp.loc[(ccode, slice(None), slice(None)), :]\n",
    "    if case[\"howmany_iam\"][0] == 1:\n",
    "        copy_case = case.copy().reset_index()\n",
    "        if set([\"OECD\"]) == set(copy_case.iam):\n",
    "            copy_case[\"iam\"], copy_case[\"iam_fill\"] = \"IIASA\", \"OECD\"\n",
    "        elif set([\"IIASA\"]) == set(copy_case.iam):\n",
    "            copy_case[\"iam\"], copy_case[\"iam_fill\"] = \"OECD\", \"IIASA\"\n",
    "        ii_gdp = pd.concat([ii_gdp, copy_case.set_index(csi)], axis=0)\n",
    "\n",
    "ii_gdp = ypk_fn.organize_hor_to_ver(\n",
    "    ii_gdp.sort_index(axis=0), \"ccode\", [\"ssp\", \"iam\"], \"gdp\", yrs=range(2010, 2101)\n",
    ").drop([\"howmany_iam\"], axis=1)\n",
    "ii_gdp[\"unit\"] = \"millions\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "012801c9-e3df-4107-951e-63c6ccdfbb43",
   "metadata": {},
   "source": [
    "#### Attaching the population values, creating GDPpc, and log-linearly interpolating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c4f37aba-7333-4ab3-a3f2-c1b8a248bb54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d0319e30ba53418a9f79fa2680ceb394",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ii_gdppc = ii_gdp.merge(ii_pop[[\"pop\"]], how=\"left\", left_index=True, right_index=True)\n",
    "ii_gdppc[\"gdppc\"] = ii_gdppc[\"gdp\"] / ii_gdppc[\"pop\"]\n",
    "scenarios = list(lstprod(*[[f\"SSP{x}\" for x in range(1, 6)], [\"IIASA\", \"OECD\"]]))\n",
    "scen_dfs = []\n",
    "for scen in tqdm(scenarios):\n",
    "    ssp, iam = scen\n",
    "    scen_df = (\n",
    "        ii_gdppc.loc[(slice(None), slice(None), ssp, iam), [\"gdppc\"]]\n",
    "        .reset_index()\n",
    "        .drop([\"ssp\", \"iam\"], axis=1)\n",
    "        .set_index([\"ccode\", \"year\"])\n",
    "    )\n",
    "    scen_df = ypk_fn.log_lin_interpolate(\n",
    "        ypk_fn.organize_ver_to_hor(\n",
    "            scen_df, \"gdppc\", \"year\", \"ccode\", range(2010, 2101)\n",
    "        ),\n",
    "    ).reset_index()\n",
    "    scen_df[\"ssp\"], scen_df[\"iam\"] = ssp, iam\n",
    "    scen_dfs.append(scen_df.set_index([\"ccode\", \"ssp\", \"iam\"]))\n",
    "ii_gdppc = ypk_fn.organize_hor_to_ver(\n",
    "    pd.concat(scen_dfs, axis=0), \"ccode\", [\"ssp\", \"iam\"], \"gdppc\", yrs=range(2010, 2101)\n",
    ")\n",
    "ii_gdppc[\"unit\"] = \"ones\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "275b2371-3815-4355-9396-2ae589a11678",
   "metadata": {},
   "source": [
    "#### Getting the by-scenario global GDPpc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "76068d53-09ae-4b5d-9c9e-61cf8c2a4f82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e82e735e6eb4f4ca5110af93c01d701",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ii_gdppc_w_pop = ii_gdppc.merge(\n",
    "    ii_pop[[\"pop\"]], how=\"left\", left_index=True, right_index=True\n",
    ")\n",
    "ii_gdppc_w_pop[\"gdp\"] = ii_gdppc_w_pop[\"pop\"] * ii_gdppc_w_pop[\"gdppc\"]\n",
    "scen_agg_dfs = []\n",
    "for scen in tqdm(scenarios):\n",
    "    ssp, iam = scen\n",
    "    scen_agg_df = (\n",
    "        ii_gdppc_w_pop.loc[(slice(None), slice(None), ssp, iam)]\n",
    "        .reset_index()\n",
    "        .groupby([\"year\"])\n",
    "        .sum()[[\"pop\", \"gdp\"]]\n",
    "        .reset_index()\n",
    "    )\n",
    "    scen_agg_df[\"ssp\"], scen_agg_df[\"iam\"] = ssp, iam\n",
    "    scen_agg_df.set_index([\"year\", \"ssp\", \"iam\"], inplace=True)\n",
    "    scen_agg_dfs.append(scen_agg_df)\n",
    "global_df = pd.concat(scen_agg_dfs, axis=0).sort_index()\n",
    "global_df[\"gdppc\"] = global_df[\"gdp\"] / global_df[\"pop\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62dbcb64-05b7-4da0-835e-fa6d8346b463",
   "metadata": {},
   "source": [
    "#### GDPpc for countries that are not in the current projections (subbing in the global GDPpc), and attaching it with the existing projections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "30523a73-509e-4ba4-ae81-987cf3ceacea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6bfe6652ca2f4a99b23005a33261d468",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/65 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "gdppc_yesproj = np.sort(ii_gdppc.index.get_level_values(\"ccode\").unique())\n",
    "gdppc_noproj = np.setdiff1d(sset.ALL_ISOS, gdppc_yesproj)\n",
    "missing_gdps = []\n",
    "for iso in tqdm(gdppc_noproj):\n",
    "    iso_df = global_df.reset_index()\n",
    "    iso_df[\"ccode\"], iso_df[\"unit\"] = iso, \"ones\"\n",
    "    iso_df.set_index([\"ccode\", \"year\", \"ssp\", \"iam\"], inplace=True)\n",
    "    missing_gdps.append(iso_df[[\"gdppc\", \"unit\"]])\n",
    "missing_gdps = pd.concat(missing_gdps, axis=0).sort_index()\n",
    "\n",
    "ii_gdppc = pd.concat([ii_gdppc, missing_gdps], axis=0).sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4b87ded6-1b9e-4b20-a7ed-df5b496083de",
   "metadata": {},
   "outputs": [],
   "source": [
    "ii_yp = ii_gdppc.merge(ii_pop, left_index=True, right_index=True, how=\"left\")\n",
    "ii_yp[\"pop_unit\"] = \"millions (of people)\"\n",
    "ii_yp[\"gdppc_unit\"] = \"ones (of USD)\"\n",
    "ii_yp[\"gdp_unit\"] = \"millions (of USD)\"\n",
    "ii_yp.drop([\"unit_x\", \"unit_y\"], inplace=True, axis=1)\n",
    "ii_yp[\"gdp\"] = ii_yp[\"gdppc\"] * ii_yp[\"pop\"]\n",
    "\n",
    "## if population is 0, then GDPpc and GDP should also be 0 (no economic activity)\n",
    "ii_yp.loc[ii_yp[\"pop\"] == 0, \"gdppc\"] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "656c4942-a9f9-400a-8c39-4bda6683b03a",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Turning the GDP and GDPpc values to 2019 USD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cee6f9c8-95de-4be6-a5e1-38d808cc2b58",
   "metadata": {},
   "outputs": [],
   "source": [
    "## inflator from 2005 to 2019\n",
    "pwt = (\n",
    "    pd.read_excel(sset.DIR_YPK_RAW / \"pwt_100.xlsx\")\n",
    "    .rename(columns={\"countrycode\": \"ccode\"})\n",
    "    .set_index([\"ccode\", \"year\"])\n",
    ")\n",
    "infla = pwt.loc[(\"USA\", 2019), \"pl_gdpo\"] / pwt.loc[(\"USA\", 2005), \"pl_gdpo\"]\n",
    "ii_yp[\"gdp\"] *= infla\n",
    "ii_yp[\"gdppc\"] *= infla"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32958206-29bc-42d9-b16c-52a5f63322dd",
   "metadata": {},
   "source": [
    "#### Organizing and exporting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "90014b99-5414-4ded-b19b-659f861cf637",
   "metadata": {},
   "outputs": [],
   "source": [
    "ii_yp = ii_yp[[\"gdp\", \"gdppc\", \"pop\", \"gdp_unit\", \"gdppc_unit\", \"pop_unit\"]].copy()\n",
    "ii_yp.to_parquet(sset.DIR_YPK_INT / \"gdp_gdppc_pop_proj_2010_2100_post_ypk6.parquet\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
