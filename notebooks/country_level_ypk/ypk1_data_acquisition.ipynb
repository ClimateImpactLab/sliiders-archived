{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5b425579-dfab-4df8-bce3-73683734d6dd",
   "metadata": {},
   "source": [
    "## Data acquisition notebook for historical, country-level GDP (`Y`), population (`P`), and capital (`K`) information\n",
    "\n",
    "In the SLIDERS workflow, historical information is only used for generating the initial (i.e., year 2010) capital stock values and creating capital and population ratios with respect to a reference year (in our case, 2019). To have some degree of usable information, we will gather and organize historical information for 1950-2019 period. In this notebook, we acquire data from various sources that will be used for this workflow.\n",
    "\n",
    "## Importing necessary modules and functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23f38671-5e1f-48c6-a008-4c80aa100a74",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8e64065-36d6-49f3-9802-d9c0939391e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import shutil\n",
    "import subprocess\n",
    "import tarfile\n",
    "import warnings\n",
    "from itertools import product as lstprod\n",
    "from pathlib import Path\n",
    "from urllib import request as urequest\n",
    "from zipfile import ZipFile\n",
    "\n",
    "import dask.distributed as dd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import rhg_compute_tools.kubernetes as rhgk\n",
    "import statsmodels.api as sm\n",
    "import xarray as xr\n",
    "from dask_gateway import Gateway\n",
    "from pandas_datareader import wb as dr_wb\n",
    "from scipy.optimize import minimize as opt_min\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from sliiders import settings as sset\n",
    "\n",
    "# dask gateway setup\n",
    "gateway = Gateway()\n",
    "cluster_name = sset.DASK_LATEST_WORKER_IMAGE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "46c424cd-022c-4590-a215-42564de40a86",
   "metadata": {},
   "outputs": [],
   "source": [
    "## shorthand for the directory\n",
    "os.makedirs(sset.DIR_YPK_RAW, exist_ok=True)\n",
    "os.makedirs(sset.DIR_LITPOP_RAW, exist_ok=True)\n",
    "os.makedirs(sset.DIR_GEG15_RAW, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "829dd79f-7d44-430d-9210-fa928c7b3683",
   "metadata": {},
   "source": [
    "## Fetching all raw data from various sources\n",
    "\n",
    "### Penn World Tables 10.0 (PWT 10.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dee44aa6-4413-4aa0-9a99-c1e0e5ff9227",
   "metadata": {},
   "outputs": [],
   "source": [
    "## PWT10.0\n",
    "pwt100_data = pd.read_excel(\"https://www.rug.nl/ggdc/docs/pwt100.xlsx\", sheet_name=2)\n",
    "\n",
    "## PWT10.0 capital details\n",
    "pwt100_data_K = pd.read_excel(\n",
    "    \"https://www.rug.nl/ggdc/docs/pwt100-capital-detail.xlsx\", sheet_name=2\n",
    ")\n",
    "\n",
    "pwt_filenames = [\"pwt_100.xlsx\", \"pwt_K_detail_100.xlsx\"]\n",
    "for i, data in enumerate([pwt100_data, pwt100_data_K]):\n",
    "    data.to_excel(\n",
    "        excel_writer=(sset.DIR_YPK_RAW / pwt_filenames[i]),\n",
    "        sheet_name=\"Sheet1\",\n",
    "        index=False,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ee3de57-cce6-40a6-b33f-d020ae0091b5",
   "metadata": {},
   "source": [
    "### Maddison Project Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5a8811da-56e7-43e8-a439-6b6c93d30ae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "madd = pd.read_excel(\n",
    "    \"https://www.rug.nl/ggdc/historicaldevelopment/maddison/data/mpd2020.xlsx\",\n",
    "    sheet_name=2,\n",
    ")\n",
    "madd.to_excel(\n",
    "    excel_writer=(sset.DIR_YPK_RAW / \"maddison_project.xlsx\"),\n",
    "    index=False,\n",
    "    sheet_name=\"Sheet1\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47858fdb-8ca9-4dcf-aa48-97055e178936",
   "metadata": {},
   "source": [
    "### World Bank WDI: Investment-to-GDP ratio, GDP and GDPpc (nominal and PPP), and Population"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b1116d48-3f5c-4c55-b80a-0101bef7a1ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "## country name and iso3 country code information\n",
    "country_info = dr_wb.get_countries()[[\"name\", \"iso3c\"]].rename(\n",
    "    columns={\"name\": \"country\", \"iso3c\": \"ccode\"}\n",
    ")\n",
    "\n",
    "## relevant indicator information for the `dr_wb` module to fetch the variables\n",
    "wbwdi_indicators = [\n",
    "    \"SP.POP.TOTL\",  ## population\n",
    "    \"NE.GDI.FTOT.ZS\",  ## investment-to-GDP ratio\n",
    "    \"NY.GDP.MKTP.PP.KD\",  ## GDP PPP\n",
    "    \"NY.GDP.PCAP.PP.KD\",  ## GDP per capita PPP\n",
    "    \"NY.GDP.MKTP.KD\",  ## GDP nominal\n",
    "    \"NY.GDP.PCAP.KD\",  ## GDP per capita nominal\n",
    "]\n",
    "\n",
    "j = 0\n",
    "for indi in wbwdi_indicators:\n",
    "    indi_info = (\n",
    "        dr_wb.download(indicator=indi, country=\"all\", start=1950, end=2020)\n",
    "        .reset_index()\n",
    "        .astype({\"year\": \"int64\"})\n",
    "        .merge(country_info, on=[\"country\"], how=\"left\")\n",
    "        .set_index([\"ccode\", \"year\"])\n",
    "    )\n",
    "\n",
    "    if j == 0:\n",
    "        j += 1\n",
    "        wbwdi_info = indi_info.copy()\n",
    "    else:\n",
    "        wbwdi_info = wbwdi_info.merge(\n",
    "            indi_info.drop([\"country\"], axis=1),\n",
    "            left_index=True,\n",
    "            right_index=True,\n",
    "            how=\"outer\",\n",
    "        )\n",
    "\n",
    "## excluding those that have no information and saving the data\n",
    "wb_info_vars = [x for x in wbwdi_info.columns if x != \"country\"]\n",
    "wbwdi_info = wbwdi_info.loc[~pd.isnull(wbwdi_info[wb_info_vars]).all(axis=1), :]\n",
    "wbwdi_info.to_parquet(sset.DIR_YPK_RAW / \"wdi_pop_iy_gdp.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0294cbda-982d-4e6f-8e75-17d333ac8eb6",
   "metadata": {},
   "source": [
    "### WB WDI: exchange rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cc9547f7-303c-40b6-b539-25961e4a49bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "## country name and iso3 country code information\n",
    "country_info = dr_wb.get_countries()[[\"name\", \"iso3c\"]].rename(\n",
    "    columns={\"name\": \"country\", \"iso3c\": \"ccode\"}\n",
    ")\n",
    "\n",
    "xr_code = \"PA.NUS.FCRF\"\n",
    "xr_wb = dr_wb.download(indicator=xr_code, country=\"all\", start=1950, end=2019)\n",
    "xr_wb = (\n",
    "    xr_wb.reset_index()\n",
    "    .astype({\"year\": \"int64\"})\n",
    "    .merge(country_info, on=[\"country\"], how=\"left\")\n",
    ")\n",
    "(\n",
    "    xr_wb.set_index([\"ccode\", \"year\"])\n",
    "    .rename(columns={xr_code: \"xrate\"})\n",
    "    .to_parquet(sset.DIR_YPK_RAW / \"wdi_xr.parquet\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d259b214-c59b-40b6-9643-ab37cdf959aa",
   "metadata": {},
   "source": [
    "### UN WPP populations (overall and by-population-group data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "66e11a5f-4e06-4420-9f89-21085f1f9d60",
   "metadata": {},
   "outputs": [],
   "source": [
    "## overall information\n",
    "un_df = pd.read_csv(\n",
    "    \"https://population.un.org/wpp/Download/Files/\"\n",
    "    \"1_Indicators%20(Standard)/CSV_FILES/WPP2019_TotalPopulationBySex.csv\"\n",
    ")\n",
    "\n",
    "## by_age_group\n",
    "by_age = pd.read_csv(\n",
    "    \"https://population.un.org/wpp/Download/Files/1_Indicators\"\n",
    "    \"%20(Standard)/CSV_FILES/WPP2019_PopulationByAgeSex_Medium.csv\"\n",
    ")\n",
    "\n",
    "## exporting\n",
    "un_df.to_csv(sset.DIR_YPK_RAW / \"UN_WPP2019_TotalPopulation.csv\", index=False)\n",
    "by_age.to_csv(sset.DIR_YPK_RAW / \"UN_WPP2019_Population_by_Age.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7d39ab6-9471-4e93-a4d6-086307121505",
   "metadata": {},
   "source": [
    "### Ã…land Island GDP and population\n",
    "\n",
    "We will keep the format and data unaltered, but change the file name to be more human-readable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "133ca501-45e7-4030-8b69-432ce57195c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "## GDP information\n",
    "ala_gdp = pd.read_excel(\n",
    "    \"https://www.asub.ax/sites/www.asub.ax/files/attachments/page/nr005en.xls\",\n",
    "    header=3,\n",
    ")\n",
    "\n",
    "## population\n",
    "ala_pop_link = (\n",
    "    \"https://www.asub.ax/sites/www.asub.ax/files/attachments/page/alv01_aland_faroe\"\n",
    "    \"_islands_and_greenland_-_an_overview_with_comparable_data.xlsx\"\n",
    ")\n",
    "ala_pop = pd.read_excel(\n",
    "    ala_pop_link,\n",
    "    header=2,\n",
    "    sheet_name=\"Population development\",\n",
    ")\n",
    "\n",
    "## exporitng\n",
    "ala_gdp.to_excel(sset.DIR_YPK_RAW / \"aland_gdp.xlsx\", index=False)\n",
    "ala_pop.to_excel(sset.DIR_YPK_RAW / \"aland_pop.xlsx\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "198a3257-9232-47c4-93d5-739085394506",
   "metadata": {},
   "source": [
    "### LitPop (Eberenz et al. 2020, Earth Syst. Sci. Data)\n",
    "\n",
    "#### Download Data from the Internet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c9377cf2-c306-4a56-b317-dafbed61f689",
   "metadata": {},
   "outputs": [],
   "source": [
    "## directory for the litpop dataset to be stored in\n",
    "direc = sset.DIR_LITPOP_RAW\n",
    "\n",
    "\n",
    "def litpop_download(link, direc=direc):\n",
    "    \"\"\"Given a URL link, downloads (LitPop-related) data from the web and saves it in\n",
    "    the specified local directory. The file name is parsed so that anything after the\n",
    "    string `?sequence` is dropped (e.g., `file.txt?sequence=..` to `file.txt`).\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    link : str\n",
    "        URL link for the file online\n",
    "    direc : str\n",
    "        directory for\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    None, but saves the file downloaded from online to `direc`.\n",
    "\n",
    "    \"\"\"\n",
    "    stop = link.find(\"?sequence\")\n",
    "    start = link.rfind(\"/\", 0, stop) + 1\n",
    "    urequest.urlretrieve(link, direc / link[start:stop])\n",
    "\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f3a94f1f-31a5-44f3-9bab-2bb00a2dbfa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "link_base = (\n",
    "    \"https://www.research-collection.ethz.ch/bitstream/handle/20.500.11850/331316\"\n",
    ")\n",
    "\n",
    "## readme, data, normalized data, and metadata\n",
    "links = [\n",
    "    link_base + \"/_readme_v1_2.txt?sequence=18&isAllowed=y\",\n",
    "    link_base + \"/LitPop_v1_2.tar?sequence=16&isAllowed=y\",\n",
    "    link_base + \"/Lit_Pop_norm_v1.tar?sequence=4&isAllowed=y\",\n",
    "    link_base + \"/_metadata_countries_v1_2.csv?sequence=12&isAllowed=y\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "461a4f17-7122-4fdd-af33-121d05c6189f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## cluster setup\n",
    "N_CLUSTER = len(links)\n",
    "cluster = gateway.new_cluster(worker_image=cluster_name, profile=\"micro\")\n",
    "client = cluster.get_client()\n",
    "cluster.scale(N_CLUSTER)\n",
    "cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd6d30b9-aa63-4197-8a00-ffc2de3890a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Takes approximately 20 minutes\n",
    "futures = client.map(litpop_download, links)\n",
    "dd.progress(futures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b627b150-bc16-4a93-a3a2-c49d3f1696da",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster.scale(0)\n",
    "client.close()\n",
    "cluster.close()\n",
    "cluster.shutdown()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97c81f17-927a-4631-a65c-82532817c2c0",
   "metadata": {},
   "source": [
    "#### Un-tar and clear storage\n",
    "\n",
    "We only un-tar the regular (not normalized) LitPop data here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "433bbff5-4be2-4086-8cbc-5ab2b37407d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# un-tar\n",
    "regular_litpop = sset.DIR_LITPOP_RAW / \"LitPop_v1_2.tar\"\n",
    "with tarfile.open(regular_litpop) as file:\n",
    "    file.extractall(sset.DIR_LITPOP_RAW)\n",
    "\n",
    "# clear storage for the existing tar file\n",
    "os.remove(regular_litpop)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cc60b86-3f35-4710-b064-4eac5c375223",
   "metadata": {},
   "source": [
    "### GEG-15\n",
    "\n",
    "We download 2'30\" GEG15 and unzip."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c55a7c58-deb3-4ff1-8fa4-0c88c4b19b57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Popen: returncode: None args: ['unzip', '/gcs/rhg-data/impactlab-rhg/coasta...>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  /gcs/rhg-data/impactlab-rhg/coastal/sliiders/raw/exposure/asset_value/geg15/gar-exp.zip\n",
      "  inflating: /gcs/rhg-data/impactlab-rhg/coastal/sliiders/raw/exposure/asset_value/geg15/gar-exp/gar_exp.shx  \n",
      "  inflating: /gcs/rhg-data/impactlab-rhg/coastal/sliiders/raw/exposure/asset_value/geg15/gar-exp/gar_exp.dbf  \n",
      "  inflating: /gcs/rhg-data/impactlab-rhg/coastal/sliiders/raw/exposure/asset_value/geg15/gar-exp/gar_exp.prj  \n",
      "  inflating: /gcs/rhg-data/impactlab-rhg/coastal/sliiders/raw/exposure/asset_value/geg15/gar-exp/gar_exp.shp  \n"
     ]
    }
   ],
   "source": [
    "# downloading\n",
    "zip_url = (\n",
    "    \"https://data.humdata.org/dataset/1c9cf1eb-c20a-4a06-8309-9416464af746/\"\n",
    "    \"resource/e321d56d-022e-4070-80ac-f7860646408d/download/gar-exp.zip\"\n",
    ")\n",
    "zip_path = sset.DIR_GEG15_RAW / \"gar-exp.zip\"\n",
    "urequest.urlretrieve(zip_url, zip_path)\n",
    "\n",
    "# unzipping\n",
    "outpath = sset.DIR_GEG15_RAW / zip_path.stem\n",
    "os.makedirs(outpath, exist_ok=True)\n",
    "subprocess.Popen([\"unzip\", f\"{zip_path}\", \"-d\", f\"{outpath}\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9825c837-4c1a-47ad-90cd-9d65a18c084d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove zip file (use after unzipping)\n",
    "os.remove(zip_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11068aec-7ef1-426a-b70e-e1f6b55c4e31",
   "metadata": {},
   "source": [
    "## Further data requiring separate instructions\n",
    "\n",
    "In all cases, we will download these in the directory specified in `sset.DIR_YPK_RAW`.\n",
    "\n",
    "### CIA World Factbook (compiled by Coleman [2020]; the version that is utilized in this workflow)\n",
    "\n",
    "1. Travel to this [link](https://github.com/iancoleman/cia_world_factbook_api) (credit to Coleman [2020]), and scroll down to the `readme.md`.\n",
    "2. In the **Data** section of the `readme.md` file, there should be a link on \"Historical\"; click on this link to travel to a `mega.nz` website having `weekly_json.7z` file.\n",
    "3. After checking that the filename to download is `weekly_json.7z`, download the said file by clicking on the \"Download\" button.\n",
    "4. When download is successful, import `weekly_json.7z` to the preferred directory (`sset.DIR_YPK_RAW` in this implementation).\n",
    "\n",
    "### IMF investment-to-GDP ratio, population, and GDP\n",
    "\n",
    "1. Travel to this [link](https://www.imf.org/en/Publications/SPROLLs/world-economic-outlook-databases#sort=%40imfdate%20descending) to get to the World Economic Outlook Databases page.\n",
    "2. Click on the latest \"World Economic Outlook Database\" link on the page; for our purposes, we have used the latest available one, which was \"World Economic Outlook Database, October 2021\" (may be updated in the future).\n",
    "3. Click \"By Countries\", then click \"ALL COUNTRIES\", then click \"CONTINUE\" on the page that says \"Select Countries.\"\n",
    "4. Under the \"NATIONAL ACCOUNTS\" tab, check the following categories:\n",
    "   - Gross domestic product, current prices (U.S. DOLLARS)\n",
    "   - Gross domestic product per capita, current prices (U.S. DOLLARS)\n",
    "   - Gross domestic product per capita, constant prices (PURCHASING POWER PARITY; 2017 INTERNATIONAL DOLLARS)\n",
    "   - Total investment (PERCENT OF GDP)\n",
    "5. Under the \"PEOPLE\" tab, check the category \"Population,\" then click on \"CONTINUE.\"\n",
    "6. Under the tab \"DATE RANGE,\" use the earliest year for \"Start Year\" (1980, in our case), and the latest non-future year for \"End Year\" (2020, in our case).\n",
    "7. Under the tab \"ADVANCED SETTINGS\", click on \"ISO Alpha-3 Code\" for getting country codes. \n",
    "8. Click on \"PREPARE REPORT.\" Then, click on \"DOWNLOAD REPORT.\" Saved data should be in Excel format and be named `WEO_Data.xls`.\n",
    "9. Open the said file on Excel, and re-save it in a preferred format of choice (we chose `.xlsx`); this is because the original file formatting is incompatible with Python and causes the error `ValueError: Excel file format cannot be determined, you must specify an engine manually.`\n",
    "\n",
    "### UN Statistics National Accounts (Analysis of Main Aggregates, GDP per capita information)\n",
    "\n",
    "1. Travel to this [link](https://unstats.un.org/unsd/snaama/Basic) to get to the UN Statistics National Accounts search page.\n",
    "2. Select all countries and all years available, and select \"GDP, Per Capita GDP - US Dollars\"\n",
    "3. Select \"Export to CSV\", and you will download the file `Results.csv`. Rename this file as `un_snaama_nom_gdppc.csv`.\n",
    "\n",
    "### OECD: region-level population information \n",
    "\n",
    "1. Go to the following OECD Stat website: link [here](https://stats.oecd.org/)\n",
    "2. On the left, find the header \"Regions and Cities\" and click the \"+\" button.\n",
    "3. From the drop down menu, click on \"Regional Statistics\".\n",
    "4. Again from the drop down menu, click on \"Regional Demography.\"\n",
    "5. Finally, select \"Population by 5-year age groups, small regions TL3.\"\n",
    "6. Download the file by selecting \"Export,\" then \"Text File (CSV).\"\n",
    "7. When a pop-up appears, select \"Default format\" then \"Download.\"\n",
    "8. Load it to a folder of your choice on the Jupyterlab setting.\n",
    "9. Finally, move the said file to the desired location; in our case, we renamed the file `REGION_DEMOGR.csv` (due to the file name having random-ish numeric parts).\n",
    "\n",
    "### OECD: region-level GDP (PPP 2015, in millions) information\n",
    "\n",
    "1. Go to the following OECD Stat website: link [here](https://stats.oecd.org/)\n",
    "2. On the left, find the header \"Regions and Cities\" and click the \"+\" button.\n",
    "3. From the drop down menu, click on \"Regional Statistics\".\n",
    "4. Again from the drop down menu, click on \"Regional Economy.\"\n",
    "5. Finally, select \"Gross Domestic Product, Small regions TL3.\"\n",
    "6. Download the file by selecting \"Export,\" then \"Text File (CSV).\"\n",
    "7. When a pop-up appears, select \"Default format\" then \"Download.\"\n",
    "8. Load it to a folder of your choice on the Jupyterlab setting.\n",
    "9. Finally, move the said file to the desired location; in our case, we renamed the file `REGION_ECONOM.csv` (due to the file name having random-ish numeric parts).\n",
    "\n",
    "### IIASA and OECD models' GDP and population projections (2010-2100, every 5 years)\n",
    "\n",
    "1. Go to the following IIASA SSP Database website: link [here](https://tntcat.iiasa.ac.at/SspDb); you may need to register and create your log-in.\n",
    "2. In the above tabs, there is a tab called \"Download\"; click on it.\n",
    "3. Under \"SSP Database Version 2 Downloads (2018)\" and under the sub-header \"Basic Elements\", there is a download link for `SspDb_country_data_2013-06-12.csv.zip`. Click and download the said `.zip` file.\n",
    "4. Extract and save the `SspDb_country_data_2013-06-12.csv`. Again, for our purposes, we save this in `sset.DIR_YPK_RAW`.\n",
    "\n",
    "### LandScan 2019\n",
    "\n",
    "1. To download this dataset, you need to first apply for an Oak Ridge National Laboratory account (link [here](https://landscan.ornl.gov/user/apply)).\n",
    "2. After having gained access, go to the said website, click on \"DOWNLOAD\" -> \"LandScan Datasets\" -> \"Continue to download\" next to LandScan 2019.\n",
    "3. Click on \"By downloading LandScan 2019 I agree to the above terms\" in the following webpage; this will download the file `LandScan Global 2019.zip`. We save this in `sset.DIR_LANDSCAN_RAW`."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
