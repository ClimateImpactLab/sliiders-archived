{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Combine exposure tiles to construct with-elevation, without-elevation, and area-by-elevation exposure parquets\n",
    "Take all the 1-degree by 1-degree binned exposure tiles and combine them to form three global datasets:\n",
    "1. \"With-elevation\" binned exposure: Includes all areas with elevations up to `sset.HIGHEST_WITHELEV_EXPOSURE_METERS`\n",
    "2. \"Without-elevation\" binned exposure: Includes all global exposure\n",
    "3. Area-by-seg-adm1: For each segment and adm1 region, the total area, in square kilometers, that is closer to that segment than to any other segment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "import dask.dataframe as ddf\n",
    "import dask.distributed as dd\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import rhg_compute_tools.kubernetes as rhgk\n",
    "import rhg_compute_tools.utils as rhgu\n",
    "\n",
    "from sliiders import settings as sset\n",
    "from sliiders import spatial\n",
    "\n",
    "spatial.filter_spatial_warnings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_batches = sset.DIR_EXPOSURE_BINNED_TMP / \"batches\"\n",
    "dir_batches.mkdir(exist_ok=False)\n",
    "\n",
    "dir_seg_batches = sset.DIR_EXPOSURE_BINNED_TMP / \"segment_area_batches\"\n",
    "dir_seg_batches.mkdir(exist_ok=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define batching function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@rhgu.block_globals\n",
    "def run_batch(batch_num, batch_size, in_paths, dir_batches, include_tile_name=False):\n",
    "    exp = []\n",
    "    batch_paths = in_paths[\n",
    "        batch_num * batch_size : min((batch_num + 1) * batch_size, len(in_paths))\n",
    "    ]\n",
    "\n",
    "    for filename in batch_paths:\n",
    "        try:\n",
    "            df = pd.read_csv(filename, index_col=None, header=0)\n",
    "            if include_tile_name:\n",
    "                df[\"filename\"] = filename.stem\n",
    "            exp.append(df)\n",
    "        except pd.errors.EmptyDataError:\n",
    "            # these are the placeholder CSVs\n",
    "            pass\n",
    "\n",
    "    exp = pd.concat(exp, axis=0, ignore_index=True)\n",
    "    if \"wetland_flag\" in exp.columns:\n",
    "        exp[\"wetland_flag\"] = exp[\"wetland_flag\"].astype(bool)\n",
    "\n",
    "    exp.to_parquet(dir_batches / f\"batch_{batch_num}.parquet\")\n",
    "\n",
    "    return 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start workers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nworkers = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client, cluster = rhgk.get_micro_cluster()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster.scale(nworkers)\n",
    "\n",
    "cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combine 1-degree tile CSVs into batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tile_paths = list(sset.DIR_EXPOSURE_BINNED_TMP_TILES.glob(\"*.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = int(len(tile_paths) / (nworkers * 2)) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shuffling the paths helps assure each worker gets CSV batches of about the same total size\n",
    "random.seed(1)\n",
    "random.shuffle(tile_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_futures = [\n",
    "    client.submit(run_batch, i, batch_size, tile_paths, dir_batches)\n",
    "    for i in range(nworkers * 2)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dd.progress(batch_futures)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combine 1-degree segment-area tile CSVs into batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seg_tile_paths = list(sset.DIR_EXPOSURE_BINNED_TMP_TILES_SEGMENT_AREA.glob(\"*.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = int(len(seg_tile_paths) / (nworkers * 2)) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shuffling the paths helps assure each worker gets CSV batches of about the same total size\n",
    "random.seed(1)\n",
    "random.shuffle(seg_tile_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_futures = [\n",
    "    client.submit(run_batch, i, batch_size, seg_tile_paths, dir_seg_batches)\n",
    "    for i in range(nworkers * 2)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dd.progress(batch_futures)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merge tile batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_ddf = ddf.read_parquet(str(dir_batches / f\"batch_*.parquet\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_ddf = exp_ddf.rename(columns={\"value\": \"asset_value\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_ddf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_dtypes = {\n",
    "    \"z_ix\": np.int32,\n",
    "    \"seg_adm\": str,\n",
    "    \"protection_zone\": np.int16,\n",
    "    \"area_km\": np.float32,\n",
    "    \"asset_value\": np.float32,\n",
    "    \"pop_landscan\": np.float32,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_ddf = exp_ddf.astype(column_dtypes).persist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_ddf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merge segment-area tile batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seg_area_ddf = ddf.read_parquet(str(dir_seg_batches / f\"batch_*.parquet\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "area_by_elev = seg_area_ddf.groupby(\n",
    "    [\"z_ix\", \"seg_adm\", \"protection_zone\", \"wetland_flag\"]\n",
    ")[\"area_km\"].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "area_by_elev = area_by_elev.persist()\n",
    "dd.progress(area_by_elev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "area_by_elev = area_by_elev.reset_index(drop=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "highest_z_ix = (\n",
    "    int(sset.HIGHEST_WITHELEV_EXPOSURE_METERS / sset.EXPOSURE_BIN_WIDTH_H) - 1\n",
    ")\n",
    "area_by_elev = area_by_elev[area_by_elev[\"z_ix\"] <= highest_z_ix]\n",
    "\n",
    "area_by_elev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ciam = (\n",
    "    area_by_elev.groupby([\"z_ix\", \"seg_adm\", \"protection_zone\", \"wetland_flag\"])[\n",
    "        \"area_km\"\n",
    "    ]\n",
    "    .sum()\n",
    "    .reset_index(drop=False)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "area_by_elev_dtypes = {\n",
    "    \"z_ix\": np.int16,\n",
    "    \"seg_adm\": \"category\",\n",
    "    \"protection_zone\": \"category\",\n",
    "    \"wetland_flag\": bool,\n",
    "    \"area_km\": np.float32,\n",
    "    \"land_area_km\": np.float32,\n",
    "    \"wetland_area_km\": np.float32,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ciam = ciam.astype({k: v for k, v in area_by_elev_dtypes.items() if k in ciam.columns})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ciam = ciam.persist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ciam_local = ciam.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def divide_area_by_elev_into_wetland_and_non_wetland(area_by_elev_local):\n",
    "    group_cols = [\n",
    "        c for c in area_by_elev_local.columns if c not in [\"wetland_flag\", \"area_km\"]\n",
    "    ]\n",
    "\n",
    "    with_wetland = area_by_elev_local.loc[area_by_elev_local[\"wetland_flag\"]]\n",
    "    without_wetland = area_by_elev_local.loc[~area_by_elev_local[\"wetland_flag\"]]\n",
    "    area_by_elev_local = pd.merge(\n",
    "        without_wetland,\n",
    "        with_wetland,\n",
    "        left_on=group_cols,\n",
    "        right_on=group_cols,\n",
    "        suffixes=(\"_no_wetland\", \"_wetland\"),\n",
    "        how=\"outer\",\n",
    "    ).reset_index(drop=True)\n",
    "\n",
    "    area_by_elev_local = area_by_elev_local.drop(\n",
    "        columns=[\"wetland_flag_no_wetland\", \"wetland_flag_wetland\"]\n",
    "    )\n",
    "\n",
    "    area_by_elev_local = area_by_elev_local.rename(\n",
    "        columns={\n",
    "            \"area_km_no_wetland\": \"land_area_km\",\n",
    "            \"area_km_wetland\": \"wetland_area_km\",\n",
    "        }\n",
    "    )\n",
    "\n",
    "    area_by_elev_local[\"land_area_km\"] = area_by_elev_local[\"land_area_km\"].fillna(0)\n",
    "    area_by_elev_local[\"wetland_area_km\"] = area_by_elev_local[\n",
    "        \"wetland_area_km\"\n",
    "    ].fillna(0)\n",
    "\n",
    "    area_by_elev_local = area_by_elev_local.astype(\n",
    "        {\n",
    "            k: v\n",
    "            for k, v in area_by_elev_dtypes.items()\n",
    "            if k in area_by_elev_local.columns\n",
    "        }\n",
    "    )\n",
    "\n",
    "    return area_by_elev_local.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ciam_local = divide_area_by_elev_into_wetland_and_non_wetland(ciam_local)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remove any old versions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sset.PATH_EXPOSURE_AREA_BY_CIAM_AND_ELEVATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sset.PATH_EXPOSURE_AREA_BY_CIAM_AND_ELEVATION.exists()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sset.PATH_EXPOSURE_AREA_BY_CIAM_AND_ELEVATION.parent.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ciam_local.to_parquet(sset.PATH_EXPOSURE_AREA_BY_CIAM_AND_ELEVATION, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.cancel(area_by_elev)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create without-elevation dataframe from with-elevation tiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_ddf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "withoutelev_ddf = exp_ddf.groupby(\n",
    "    [\"seg_adm\"],\n",
    ")[[\"asset_value\", \"pop_landscan\", \"area_km\"]].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "withoutelev_ddf = withoutelev_ddf.reset_index(drop=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "withoutelev_ddf = withoutelev_ddf.persist()\n",
    "dd.progress(withoutelev_ddf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "withoutelev_ddf = withoutelev_ddf.astype(\n",
    "    {k: v for k, v in column_dtypes.items() if k in withoutelev_ddf.columns}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "withoutelev_ddf = withoutelev_ddf.persist()\n",
    "dd.progress(withoutelev_ddf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remove any old versions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sset.PATH_EXPOSURE_BINNED_WITHOUTELEV.exists()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "withoutelev_pq_out = withoutelev_ddf.to_parquet(\n",
    "    sset.PATH_EXPOSURE_BINNED_WITHOUTELEV,\n",
    "    engine=\"pyarrow\",\n",
    "    write_index=False,\n",
    "    compute=False,\n",
    ").persist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dd.progress(withoutelev_ddf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create with-elevation parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "withelev_ddf = exp_ddf[exp_ddf[\"z_ix\"] <= highest_z_ix]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "withelev_ddf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "withelev_ddf = withelev_ddf.groupby([\"z_ix\", \"seg_adm\", \"protection_zone\"])[\n",
    "    [\"area_km\", \"asset_value\", \"pop_landscan\"]\n",
    "].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "withelev_ddf = withelev_ddf.reset_index(drop=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "withelev_ddf = withelev_ddf.persist()\n",
    "dd.progress(withelev_ddf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remove any old versions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sset.PATH_EXPOSURE_BINNED_WITHELEV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sset.PATH_EXPOSURE_BINNED_WITHELEV.exists()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "withelev_pq_out = withelev_ddf.to_parquet(\n",
    "    sset.PATH_EXPOSURE_BINNED_WITHELEV,\n",
    "    engine=\"pyarrow\",\n",
    "    write_index=False,\n",
    "    compute=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "withelev_pq_out = withelev_pq_out.persist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dd.progress(withelev_pq_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shut down cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.close()\n",
    "cluster.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make some final adjustments and checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "withelev = pd.read_parquet(sset.PATH_EXPOSURE_BINNED_WITHELEV)\n",
    "\n",
    "withoutelev = pd.read_parquet(sset.PATH_EXPOSURE_BINNED_WITHOUTELEV)\n",
    "\n",
    "area_ciam = pd.read_parquet(sset.PATH_EXPOSURE_AREA_BY_CIAM_AND_ELEVATION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_dtypes = {\n",
    "    \"z_ix\": np.int32,\n",
    "    \"seg_adm\": \"category\",\n",
    "    \"protection_zone\": np.int16,\n",
    "    \"area_km\": np.float32,\n",
    "    \"asset_value\": np.float32,\n",
    "    \"pop_landscan\": np.float32,\n",
    "}\n",
    "\n",
    "# Step through fields one-by-one to prevent memory explosion copying the whole dataframe\n",
    "for field, field_type in exp_dtypes.items():\n",
    "    withelev[field] = withelev[field].astype(field_type)\n",
    "\n",
    "for field, field_type in exp_dtypes.items():\n",
    "    if field in withoutelev.columns:\n",
    "        withoutelev[field] = withoutelev[field].astype(field_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "withelev = withelev[\n",
    "    (withelev[\"asset_value\"] > 0) | (withelev[\"pop_landscan\"] > 0)\n",
    "].reset_index(drop=True)\n",
    "\n",
    "withoutelev = withoutelev[\n",
    "    (withoutelev[\"asset_value\"] > 0) | (withoutelev[\"pop_landscan\"] > 0)\n",
    "].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_adm1(df):\n",
    "    df[\"adm1\"] = df[\"seg_adm\"].str[15:]\n",
    "    df[\"ISO\"] = df[\"adm1\"].str[:3]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "area_ciam = parse_adm1(area_ciam)\n",
    "withelev = parse_adm1(withelev)\n",
    "withoutelev = parse_adm1(withoutelev)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check against PWT 10.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ktable_full = pd.read_parquet(sset.PATH_COUNTRY_LEVEL_EXPOSURE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ktable_full = ktable_full.reset_index(drop=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ktable_full = ktable_full[ktable_full[\"year\"] == 2019].set_index(\"ccode\")[\n",
    "    [\"cn_19\", \"pop\"]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ktable = ktable_full[\"cn_19\"] * 1e6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pop = ktable_full[\"pop\"] * 1e6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "replacements = {\"XAD\": \"GBR\", \"XKO\": \"KO-\", \"XNC\": \"CYP\", \"XPI\": \"CHN\"}\n",
    "\n",
    "area_ciam[\"ISO\"] = area_ciam[\"ISO\"].apply(\n",
    "    lambda c: replacements[c] if c in replacements else c\n",
    ")\n",
    "\n",
    "withelev[\"ISO\"] = withelev[\"ISO\"].apply(\n",
    "    lambda c: replacements[c] if c in replacements else c\n",
    ")\n",
    "\n",
    "withoutelev[\"ISO\"] = withoutelev[\"ISO\"].apply(\n",
    "    lambda c: replacements[c] if c in replacements else c\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set(ktable.index) - set(withoutelev[\"ISO\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set(withoutelev[\"ISO\"].unique()) - set(ktable.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(set(withoutelev[\"ISO\"].unique()) - set(ktable.index)) == 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rescale asset value if needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "country_totals = withoutelev.groupby(\"ISO\")[\"asset_value\"].sum()\n",
    "country_totals.name = \"country_asset_value\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check = pd.DataFrame(ktable).join(country_totals, on=\"ccode\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check[\"diff\"] = check[\"cn_19\"] / check[\"country_asset_value\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If rescaling:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaling = check[[\"diff\"]]\n",
    "\n",
    "scaling[\"diff\"].max(), scaling[\"diff\"].min()\n",
    "\n",
    "withoutelev = withoutelev.join(scaling, on=\"ISO\")\n",
    "withelev = withelev.join(scaling, on=\"ISO\")\n",
    "\n",
    "withoutelev[\"asset_value\"] = withoutelev[\"asset_value\"] * withoutelev[\"diff\"]\n",
    "withelev[\"asset_value\"] = withelev[\"asset_value\"] * withelev[\"diff\"]\n",
    "\n",
    "withoutelev = withoutelev.drop(columns=[\"diff\"])\n",
    "withelev = withelev.drop(columns=[\"diff\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rescale population if needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "country_totals_landscan = withoutelev.groupby(\"ISO\")[\"pop_landscan\"].sum()\n",
    "country_totals_landscan.name = \"country_population_landscan\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check = pd.DataFrame(pop).join(country_totals_landscan, on=\"ccode\")\n",
    "check[\"diff_landscan\"] = check[\"pop\"] / check[\"country_population_landscan\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If rescaling:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaling = check[[\"diff_landscan\"]]\n",
    "\n",
    "scaling[\"diff_landscan\"].max(), scaling[\"diff_landscan\"].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "withoutelev = withoutelev.join(scaling, on=\"ISO\")\n",
    "withelev = withelev.join(scaling, on=\"ISO\")\n",
    "\n",
    "withoutelev[\"pop_landscan\"] = withoutelev[\"pop_landscan\"] * withoutelev[\"diff_landscan\"]\n",
    "withelev[\"pop_landscan\"] = withelev[\"pop_landscan\"] * withelev[\"diff_landscan\"]\n",
    "\n",
    "withoutelev = withoutelev.drop(columns=[\"diff_landscan\"])\n",
    "withelev = withelev.drop(columns=[\"diff_landscan\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "withelev[\"asset_value\"].sum() / 1e12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "withoutelev[\"asset_value\"].sum() / 1e12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "withelev[\"pop_landscan\"].sum() / 1e9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "withoutelev[\"pop_landscan\"].sum() / 1e9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "withoutelev[\"ISO\"] = withoutelev[\"ISO\"].astype(\"category\")\n",
    "withelev[\"ISO\"] = withelev[\"ISO\"].astype(\"category\")\n",
    "\n",
    "withoutelev[\"asset_value\"] = withoutelev[\"asset_value\"].astype(np.float32)\n",
    "withelev[\"asset_value\"] = withelev[\"asset_value\"].astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sset.PATH_EXPOSURE_BINNED_WITHELEV.exists()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Delete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sset.PATH_EXPOSURE_BINNED_WITHELEV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "withelev.to_parquet(sset.PATH_EXPOSURE_BINNED_WITHELEV, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sset.PATH_EXPOSURE_BINNED_WITHOUTELEV.exists()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sset.PATH_EXPOSURE_BINNED_WITHOUTELEV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "withoutelev.to_parquet(sset.PATH_EXPOSURE_BINNED_WITHOUTELEV, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "area_ciam.to_parquet(sset.PATH_EXPOSURE_AREA_BY_CIAM_AND_ELEVATION, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add `lowelev` field to CIAM-Adm1 intersections file to indicate inclusion in elevation processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ciam_adm1 = gpd.read_parquet(sset.PATH_CIAM_ADM1_VORONOI_INTERSECTIONS)\n",
    "ciam_adm1[\"lowelev\"] = ciam_adm1[\"seg_adm\"].isin(withelev[\"seg_adm\"].unique())\n",
    "ciam_adm1[\"ISO\"] = ciam_adm1[\"ISO\"].apply(\n",
    "    lambda c: replacements[c] if c in replacements else c\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ciam_adm1.to_parquet(\n",
    "    sset.PATH_CIAM_ADM1_VORONOI_INTERSECTIONS, index=False, row_group_size=500\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check that it looks good"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### withelev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "withelev_out = pd.read_parquet(sset.PATH_EXPOSURE_BINNED_WITHELEV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "withelev_out.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "withelev_out[\"asset_value\"].sum() / 1e12"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### withoutelev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "withoutelev_out = pd.read_parquet(sset.PATH_EXPOSURE_BINNED_WITHOUTELEV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "withoutelev_out.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "withoutelev_out[\"asset_value\"].sum() / 1e12"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CIAM area-by-elevation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "area = pd.read_parquet(sset.PATH_EXPOSURE_AREA_BY_CIAM_AND_ELEVATION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "area.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
