{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Augment Missing Data in LitPop with Geg-15"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are some missing countries in LitPop. This notebook fills in those areas with Geg-15 and saves the grid as a single parquet file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "\n",
    "%autoreload 2\n",
    "\n",
    "import dask.dataframe as ddf\n",
    "import geopandas as gpd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import numpy_groupies as npg\n",
    "import pandas as pd\n",
    "import regionmask\n",
    "import rhg_compute_tools.kubernetes as rhgk\n",
    "import xarray as xr\n",
    "import rioxarray\n",
    "import xesmf as xe\n",
    "from cartopy import crs as ccrs\n",
    "from cartopy import feature as cfeature\n",
    "\n",
    "from sliiders.geography import get_iso_geometry\n",
    "from sliiders.spatial import grid_ix_to_val, grid_val_to_ix\n",
    "from sliiders import settings as sset\n",
    "\n",
    "import zipfile\n",
    "from sliiders import __file__\n",
    "from pathlib import Path\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client, cluster = rhgk.get_micro_cluster()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nworkers = 16\n",
    "cluster.scale(nworkers)\n",
    "cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sliiders_dir = Path(__file__).parent\n",
    "zipf = zipfile.ZipFile(\"sliiders.zip\", \"w\", zipfile.ZIP_DEFLATED)\n",
    "for root, dirs, files in os.walk(sliiders_dir):\n",
    "    for file in files:\n",
    "        zipf.write(\n",
    "            os.path.join(root, file),\n",
    "            os.path.relpath(os.path.join(root, file), os.path.join(sliiders_dir, \"..\")),\n",
    "        )\n",
    "zipf.close()\n",
    "client.upload_file(\"sliiders.zip\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # convert litpop from csvs to a parquet file\n",
    "litpop = ddf.read_csv(str(sset.PATH_LITPOP_RAW))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "litpop = litpop.rename(columns={\"latitude\": \"lat\", \"longitude\": \"lon\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "litpop[\"value\"] = litpop[\"value\"].astype(np.float32)\n",
    "litpop[\"lat\"] = litpop[\"lat\"].astype(np.float32)\n",
    "litpop[\"lon\"] = litpop[\"lon\"].astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "litpop = litpop.repartition(npartitions=nworkers).persist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "litpop_meta = pd.read_csv(sset.DIR_LITPOP_RAW / \"_metadata_countries_v1_2.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Geodataframe for Countries with Missing LitPop Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_countries = litpop_meta[litpop_meta[\"included\"] == 0].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_countries = gpd.GeoDataFrame(\n",
    "    missing_countries,\n",
    "    geometry=get_iso_geometry(missing_countries[\"iso3\"].to_numpy()),\n",
    ")\n",
    "\n",
    "missing_countries[\"iso3\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "region_id_to_iso = litpop_meta.set_index(\"region_id\")[[\"iso3\"]]\n",
    "\n",
    "litpop = litpop.join(region_id_to_iso, on=\"region_id\").persist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geg15 = pd.read_parquet(sset.PATH_GEG15_INT, columns=[\"lon\", \"lat\", \"iso3\", \"tot_val\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geg15[\"tot_val\"] = geg15[\"tot_val\"] * 1e6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lp_iso3 = litpop[\"iso3\"].unique().compute()\n",
    "geg_iso3 = geg15[\"iso3\"].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# retrieve geg data to regrid\n",
    "def subset_relevant_geg_data(poly, geg15, buffer=1 / 48):\n",
    "    # subset geg for buffered country poly bounds\n",
    "    geg15_sub = (\n",
    "        geg15[\n",
    "            (geg15.lon >= poly.bounds[0] - buffer)\n",
    "            & (geg15.lon <= poly.bounds[2] + buffer)\n",
    "            & (geg15.lat >= poly.bounds[1] - buffer)\n",
    "            & (geg15.lat <= poly.bounds[3] + buffer)\n",
    "        ][[\"lon\", \"lat\", \"tot_val\"]].reset_index(drop=True)\n",
    "        #         .compute()\n",
    "    )\n",
    "\n",
    "    if geg15_sub.shape[0] == 0:\n",
    "        return None\n",
    "\n",
    "    subset = geg15_sub.set_index([\"lat\", \"lon\"]).to_xarray()\n",
    "\n",
    "    subset[\"mask\"] = poly_mask(poly, subset)\n",
    "\n",
    "    if subset.tot_val.where(subset.mask == 1).sum() <= 0:\n",
    "        return None\n",
    "\n",
    "    return subset\n",
    "\n",
    "\n",
    "def create_grid(subset, resolution, add_cell_corners=False):\n",
    "\n",
    "    masked_lon = subset.lon.where((subset.mask > 0) & (subset.tot_val.notnull()))\n",
    "    masked_lat = subset.lat.where((subset.mask > 0) & (subset.tot_val.notnull()))\n",
    "\n",
    "    # construct destination grid with mask holder variable\n",
    "    x1, y1 = np.floor((masked_lon.lon.min().item(), masked_lat.lat.min().item()))\n",
    "    x2, y2 = np.ceil((masked_lon.lon.max().item(), masked_lat.lat.max().item()))\n",
    "\n",
    "    lat = np.arange(y1 + resolution / 2, y2, resolution)\n",
    "    lon = np.arange(x1 + resolution / 2, x2, resolution)\n",
    "\n",
    "    ds_out = xr.Dataset(\n",
    "        coords={\n",
    "            \"lat\": lat,\n",
    "            \"lon\": lon,\n",
    "        }\n",
    "    )\n",
    "\n",
    "    if add_cell_corners:\n",
    "        ds_out.coords[\"lat_b\"] = (ds_out.lat.min().item() - resolution / 2) + np.arange(\n",
    "            len(ds_out.lat) + 1\n",
    "        ) * resolution\n",
    "        ds_out.coords[\"lon_b\"] = (ds_out.lon.min().item() - resolution / 2) + np.arange(\n",
    "            len(ds_out.lon) + 1\n",
    "        ) * resolution\n",
    "\n",
    "    return ds_out\n",
    "\n",
    "\n",
    "def poly_mask(poly, grid):\n",
    "    mask_grid = grid.copy()\n",
    "    mask_grid[\"mask\"] = (\n",
    "        [\"lat\", \"lon\"],\n",
    "        np.full((len(mask_grid.lat), len(mask_grid.lon)), 1, np.int32),\n",
    "    )\n",
    "\n",
    "    mask_grid = mask_grid.rio.set_spatial_dims(x_dim=\"lon\", y_dim=\"lat\", inplace=True)\n",
    "    mask_grid = mask_grid.rio.write_crs(\"epsg:4326\", inplace=True)\n",
    "\n",
    "    clipped = mask_grid.rio.clip([poly], drop=False, all_touched=True)\n",
    "    clipped = (clipped == 1).astype(np.int32)\n",
    "\n",
    "    return clipped.mask.dims, clipped.mask.values\n",
    "\n",
    "\n",
    "def make_land_weights(subset, poly, out_resolution, in_resolution):\n",
    "\n",
    "    print(\"Creating grids...\")\n",
    "    # create grid at out_resolution with grid cell edges at a whole lat and lon values\n",
    "    out_grid = create_grid(subset, resolution=out_resolution, add_cell_corners=True)\n",
    "\n",
    "    # create grid at in_resolution with grid cell edges at a whole lat and lon values\n",
    "    in_grid = create_grid(subset, resolution=in_resolution, add_cell_corners=True)\n",
    "\n",
    "    # create grid cell id for in_grid\n",
    "    in_grid[\"id5x\"] = (\n",
    "        [\"lat\", \"lon\"],\n",
    "        np.arange(in_grid.lat.shape[0] * in_grid.lon.shape[0]).reshape(\n",
    "            (in_grid.lat.shape[0], in_grid.lon.shape[0])\n",
    "        ),\n",
    "    )\n",
    "\n",
    "    # apply in_grid grid cell id to out_grid cells\n",
    "    out_grid[\"idx5\"] = in_grid.reindex_like(\n",
    "        out_grid, method=\"nearest\", tolerance=in_resolution / 2\n",
    "    ).id5x\n",
    "\n",
    "    print(\"Creating land mask...\")\n",
    "    out_grid[\"mask\"] = (\n",
    "        regionmask.Regions([poly], numbers=[1])\n",
    "        .mask(out_grid.lon.values, out_grid.lat.values)\n",
    "        .fillna(0)\n",
    "    )\n",
    "\n",
    "    print(\"Constructing land weights...\")\n",
    "    in_grid[\"land_weights\"] = (\n",
    "        [\"lat\", \"lon\"],\n",
    "        npg.aggregate(\n",
    "            group_idx=out_grid.idx5.values.flatten(),\n",
    "            a=out_grid.mask.values.flatten(),\n",
    "            fill_value=0,\n",
    "            func=\"sum\",\n",
    "        ).reshape(in_grid.id5x.shape)\n",
    "        / ((in_resolution / out_resolution) ** 2),\n",
    "    )\n",
    "\n",
    "    return in_grid\n",
    "\n",
    "\n",
    "def prep_geg_for_regrid(\n",
    "    poly, geg15, geg_res=sset.GEG_GRID_WIDTH, litpop_res=sset.LITPOP_GRID_WIDTH\n",
    "):\n",
    "\n",
    "    # get relevant geg data given poly of interest\n",
    "    subset = subset_relevant_geg_data(poly, geg15, geg_res / 2)\n",
    "    if subset is None:\n",
    "        return None\n",
    "\n",
    "    # construct land weights\n",
    "    weights = make_land_weights(subset, poly, litpop_res, geg_res)\n",
    "\n",
    "    # add corners for conservative regrid\n",
    "    subset.coords[\"lat_b\"] = (subset.lat.min().item() - geg_res / 2) + np.arange(\n",
    "        len(subset.lat) + 1\n",
    "    ) * geg_res\n",
    "    subset.coords[\"lon_b\"] = (subset.lon.min().item() - geg_res / 2) + np.arange(\n",
    "        len(subset.lon) + 1\n",
    "    ) * geg_res\n",
    "\n",
    "    # regrid landweights onto geg grid\n",
    "    regridder = xe.Regridder(weights, subset, \"conservative\")\n",
    "    land_weights_regrid = regridder(weights)\n",
    "\n",
    "    # normalize using amount of land per cell\n",
    "    weights = geg_res**2\n",
    "    subset[\"tot_val_norm\"] = (\n",
    "        subset.tot_val.where(land_weights_regrid.land_weights > 0) / weights\n",
    "    )\n",
    "\n",
    "    # drop out if all null data --> no asset value on relevant land\n",
    "    if (\n",
    "        subset.tot_val_norm.where((subset.mask > 0) & subset.tot_val_norm.notnull())\n",
    "        .notnull()\n",
    "        .sum()\n",
    "        == 0\n",
    "    ):\n",
    "        return None\n",
    "\n",
    "    return subset\n",
    "\n",
    "\n",
    "def regrid_geg(\n",
    "    poly, geg15, geg_res=sset.GEG_GRID_WIDTH, litpop_res=sset.LITPOP_GRID_WIDTH\n",
    "):\n",
    "\n",
    "    geg_sub = prep_geg_for_regrid(poly, geg15, geg_res, litpop_res)\n",
    "\n",
    "    if geg_sub is None:\n",
    "        return None\n",
    "\n",
    "    out_grid = create_grid(geg_sub, resolution=litpop_res)\n",
    "\n",
    "    regridder = xe.Regridder(geg_sub, out_grid, \"nearest_s2d\")\n",
    "\n",
    "    geg_regridded = regridder(geg_sub)\n",
    "\n",
    "    mask_dims, mask = poly_mask(poly, geg_regridded[[\"lat\", \"lon\"]])\n",
    "    geg_regridded[\"tot_val\"] = (geg_regridded.tot_val_norm * (litpop_res**2)).where(\n",
    "        mask == 1\n",
    "    )\n",
    "\n",
    "    return geg_regridded"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regrid GEG for Missing Countries in LitPop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_dict = {}\n",
    "for territory in sset.ISOS_IN_GEG_NOT_LITPOP:\n",
    "    print(territory)\n",
    "    territory_shape = (\n",
    "        missing_countries[missing_countries[\"iso3\"] == territory].iloc[0].geometry\n",
    "    )\n",
    "    out_dict[territory] = regrid_geg(territory_shape, geg15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check Regridding Looks Good"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_exposure(ax, title, data, poly, vmin=None, vmax=None):\n",
    "    ax.set_extent(\n",
    "        [poly.bounds[0] - 1, poly.bounds[2] + 1, poly.bounds[1] - 1, poly.bounds[3] + 1]\n",
    "    )\n",
    "    ax.coastlines(\"10m\", linewidth=0.5, edgecolor=\"tab:orange\")\n",
    "\n",
    "    adm0 = cfeature.NaturalEarthFeature(\n",
    "        category=\"cultural\",\n",
    "        name=\"admin_0_boundary_lines_land\",\n",
    "        scale=\"10m\",\n",
    "        facecolor=\"none\",\n",
    "    )\n",
    "\n",
    "    ax.add_feature(adm0, edgecolor=\"tab:orange\", linewidth=0.1)\n",
    "\n",
    "    data.where(data > 0.0000001).plot(\n",
    "        cmap=\"YlGnBu\",\n",
    "        norm=matplotlib.colors.LogNorm(vmin=vmin, vmax=vmax),\n",
    "        ax=ax,\n",
    "        cbar_kwargs={\"shrink\": 0.5, \"label\": \"\"},\n",
    "    )\n",
    "\n",
    "    ax.add_geometries(\n",
    "        [poly], ccrs.PlateCarree(), facecolor=\"none\", edgecolor=\"r\", linewidth=0.3\n",
    "    )\n",
    "    ax.set_title(title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How does the regridding look?\n",
    "%matplotlib inline\n",
    "\n",
    "plot_dict = out_dict\n",
    "\n",
    "pc_transform = ccrs.PlateCarree()\n",
    "fig, axs = plt.subplots(\n",
    "    figsize=((3 * 3), (3 * 4)),\n",
    "    dpi=500,\n",
    "    ncols=3,\n",
    "    nrows=3,\n",
    "    subplot_kw={\"projection\": pc_transform},\n",
    ")\n",
    "\n",
    "axs = axs.flatten()\n",
    "for ax, tup in zip(axs, plot_dict.items()):\n",
    "    iso = tup[0]\n",
    "    out = tup[1]\n",
    "    row = missing_countries[missing_countries.iso3 == iso].iloc[0]\n",
    "    poly = row.geometry\n",
    "    plot_exposure(ax, iso, out[\"tot_val\"], poly)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add Regridded Data into LitPop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# swap from value to integer indexing\n",
    "litpop[\"lat\"] = litpop.lat.map_partitions(\n",
    "    grid_val_to_ix, cell_size=sset.LITPOP_GRID_WIDTH\n",
    ")\n",
    "litpop[\"lon\"] = litpop.lon.map_partitions(\n",
    "    grid_val_to_ix, cell_size=sset.LITPOP_GRID_WIDTH\n",
    ")\n",
    "litpop = litpop.persist()\n",
    "\n",
    "litpop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add geg data into litpop dask dataframe\n",
    "for iso, _add in out_dict.items():\n",
    "    print(iso)\n",
    "    add = _add.copy()\n",
    "    add.coords[\"lat\"] = grid_val_to_ix(add.lat.values, sset.LITPOP_GRID_WIDTH)\n",
    "    add.coords[\"lon\"] = grid_val_to_ix(add.lon.values, sset.LITPOP_GRID_WIDTH)\n",
    "\n",
    "    litpop_sub = litpop[\n",
    "        (litpop.lon >= add.lon.min().item())\n",
    "        & (litpop.lon <= add.lon.max().item())\n",
    "        & (litpop.lat >= add.lat.min().item())\n",
    "        & (litpop.lat <= add.lat.max().item())\n",
    "    ].compute()\n",
    "\n",
    "    # Mask out all MAR values below the MAR-ESH border (this border is defined by its latitude)\n",
    "    if iso == \"ESH\":\n",
    "        litpop_sub = litpop_sub.loc[\n",
    "            ~(litpop_sub[\"iso3\"] == \"MAR\")\n",
    "            | ~(litpop_sub[\"lat\"] <= get_iso_geometry(\"ESH\").bounds[3])\n",
    "        ].copy()\n",
    "\n",
    "    litpop_sub = litpop_sub.set_index([\"lat\", \"lon\"]).to_xarray()\n",
    "\n",
    "    add = add.rename({\"tot_val\": \"value\"})\n",
    "\n",
    "    add[\"iso3\"] = ([\"lat\", \"lon\"], np.where((~np.isnan(add[\"value\"])), iso, None))\n",
    "\n",
    "    litpop_sub[\"new_iso3\"] = add[\"iso3\"]\n",
    "    litpop_sub[\"iso3\"] = xr.where(\n",
    "        litpop_sub[\"new_iso3\"].isnull(), litpop_sub[\"iso3\"], litpop_sub[\"new_iso3\"]\n",
    "    )\n",
    "    litpop_sub[\"new_value\"] = add[\"value\"]\n",
    "    litpop_sub[\"value\"] = xr.where(\n",
    "        litpop_sub[\"new_value\"].isnull(), litpop_sub[\"value\"], litpop_sub[\"new_value\"]\n",
    "    )\n",
    "\n",
    "    mmed = xr.merge([litpop_sub[[\"value\", \"iso3\"]], add[[\"value\", \"iso3\"]]])\n",
    "\n",
    "    litpop_m_sub = litpop[\n",
    "        ~(\n",
    "            (litpop.lon >= add.lon.min().item())\n",
    "            & (litpop.lon <= add.lon.max().item())\n",
    "            & (litpop.lat >= add.lat.min().item())\n",
    "            & (litpop.lat <= add.lat.max().item())\n",
    "        )\n",
    "    ]\n",
    "\n",
    "    to_append = mmed[[\"value\", \"iso3\"]].to_dataframe().dropna().reset_index()\n",
    "\n",
    "    # TODO figure out what's going on here--sometimes index isn't automatically named by `to_dataframe()`\n",
    "    to_append = to_append.rename(columns={\"level_0\": \"lat\", \"level_1\": \"lon\"})\n",
    "    litpop = litpop_m_sub.append(to_append).persist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prep vars for saving\n",
    "litpop[\"y_ix\"] = litpop[\"lat\"].astype(np.int16)\n",
    "litpop[\"x_ix\"] = litpop[\"lon\"].astype(np.int16)\n",
    "litpop[\"value\"] = litpop[\"value\"].astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "litpop = litpop.persist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_iso3 = litpop[\"iso3\"].unique().compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "litpop = litpop[[\"y_ix\", \"x_ix\", \"value\"]]\n",
    "litpop = litpop[litpop[\"value\"] > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_litpop = litpop.compute()\n",
    "\n",
    "df_litpop = df_litpop.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_litpop[\"value\"] = df_litpop[\"value\"].astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_litpop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sset.PATH_EXPOSURE_BLENDED.parent.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_litpop.to_parquet(\n",
    "    sset.PATH_EXPOSURE_BLENDED,\n",
    "    index=False,\n",
    "    compression=None,\n",
    "    engine=\"fastparquet\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check To Make Sure GEG Additions Look Good"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "litpop_int = pd.read_parquet(sset.PATH_EXPOSURE_BLENDED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "litpop_int[\"lat\"] = grid_ix_to_val(litpop_int.y_ix, cell_size=sset.LITPOP_GRID_WIDTH)\n",
    "litpop_int[\"lon\"] = grid_ix_to_val(litpop_int.x_ix, cell_size=sset.LITPOP_GRID_WIDTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How does the regridding look?\n",
    "%matplotlib inline\n",
    "\n",
    "plot_dict = out_dict\n",
    "\n",
    "pc_transform = ccrs.PlateCarree()\n",
    "fig, axs = plt.subplots(\n",
    "    figsize=((3 * 3), (3 * 4)),\n",
    "    dpi=500,\n",
    "    ncols=3,\n",
    "    nrows=4,\n",
    "    subplot_kw={\"projection\": pc_transform},\n",
    ")\n",
    "\n",
    "axs = axs.flatten()\n",
    "for ax, tup in zip(axs, plot_dict.items()):\n",
    "    iso = tup[0]\n",
    "    add = tup[1]\n",
    "    row = missing_countries[missing_countries.iso3 == iso].iloc[0]\n",
    "    poly = row.geometry\n",
    "\n",
    "    litpop_sub = (\n",
    "        litpop_int[\n",
    "            (litpop_int.lon >= add.lon.min().item() - 1)\n",
    "            & (litpop_int.lon <= add.lon.max().item() + 1)\n",
    "            & (litpop_int.lat >= add.lat.min().item() - 1)\n",
    "            & (litpop_int.lat <= add.lat.max().item() + 1)\n",
    "        ]\n",
    "        .set_index([\"lat\", \"lon\"])\n",
    "        .to_xarray()\n",
    "    )\n",
    "\n",
    "    plot_exposure(ax, row.country_name, litpop_sub.value, poly)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
