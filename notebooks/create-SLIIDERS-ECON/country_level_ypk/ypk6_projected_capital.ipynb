{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3d62e24d",
   "metadata": {},
   "source": [
    "## Projecting capital stock values (2010-2100) according to Dellink et al. (2017)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e86388c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bf979ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import os\n",
    "import zipfile\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "import xarray as xr\n",
    "from dask_gateway import Gateway\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "## settings and utility functions for SLIIDERS\n",
    "from sliiders import __file__ as slfile\n",
    "from sliiders import country_level_ypk as ypk_fn\n",
    "from sliiders import settings as sset\n",
    "\n",
    "# dask gateway setup\n",
    "gateway = Gateway()\n",
    "image_name = sset.DASK_IMAGE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7de17e72",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Capital projection\n",
    "\n",
    "We incorporate historical 2010 capital stock values and projected GDP, GDPpc, and population values.\n",
    "\n",
    "### Importing and merging capital 2010 values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3419bbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "## historical data and projected gdp, gdppc, and population\n",
    "hist_df = pd.read_parquet(\n",
    "    sset.DIR_YPK_FINAL / \"gdp_gdppc_pop_capital_1950_2020.parquet\"\n",
    ")\n",
    "proj_yp_df = pd.read_parquet(\n",
    "    sset.DIR_YPK_INT / \"gdp_gdppc_pop_proj_2010_2100_post_ypk6.parquet\"\n",
    ")\n",
    "\n",
    "## merging 2010 capital values\n",
    "proj_ypk_df = proj_yp_df.merge(\n",
    "    (\n",
    "        hist_df.loc[(slice(None), 2010), [\"rnna_19\"]].rename(\n",
    "            columns={\"rnna_19\": \"capital\"}\n",
    "        )\n",
    "    ),\n",
    "    how=\"left\",\n",
    "    left_index=True,\n",
    "    right_index=True,\n",
    ")\n",
    "\n",
    "# readjusting the values to ones (of dollars and people)\n",
    "for i in [\"gdp\", \"pop\", \"capital\"]:\n",
    "    unitname = f\"{i}_unit\"\n",
    "    proj_ypk_df[i] *= 1000000\n",
    "    proj_ypk_df[unitname] = \"ones (of USD)\"\n",
    "    if i == \"pop\":\n",
    "        proj_ypk_df[unitname] = \"ones (of people)\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "782f31fb",
   "metadata": {},
   "source": [
    "### Getting the overall GDP elasticity with respect to capital\n",
    "\n",
    "We first need to calculate the overall GDP elasticity w.r.t. capital, and here we assume a simple Cobb-Douglas production function with population being an approximation of the labor force. Alternatively, we may use IIASA approximation (from Crespo Cuaresma, 2017) of the said elasticity being approximately 0.326."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f378d31f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## let us subset values for 2010\n",
    "k2010 = proj_ypk_df.loc[(slice(None), 2010), :]\n",
    "\n",
    "# since 2010 values are same across all SSP (but could be different across iams)\n",
    "# we subset SSP2 here and calculate the GDP elasticity wrt capital\n",
    "k2010_pos_y = k2010.loc[\n",
    "    (k2010.gdp > 0) & (k2010.index.get_level_values(\"ssp\") == \"SSP2\"), :\n",
    "].sort_index()\n",
    "overall_elas_ols = sm.OLS(\n",
    "    np.log(k2010_pos_y[\"gdp\"]), sm.add_constant(np.log(k2010_pos_y[[\"pop\", \"capital\"]]))\n",
    ")\n",
    "overall_elas_ols = overall_elas_ols.fit()\n",
    "\n",
    "OVERALL_E = overall_elas_ols.params[\"capital\"]\n",
    "OVERALL_E_IIASA = 0.326"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eca8cb4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for seeing the regression summary\n",
    "overall_elas_ols.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27f22a84",
   "metadata": {},
   "source": [
    "#### Calculating the initial marginal product of capital (${MPK}_{r, t_0}$, with $t_0 = 2010$) and appending other necessary information\n",
    "\n",
    "**Four options of calculating MPK**\n",
    "\n",
    "If we assume a simple, Cobb-Douglas form for the production function (i.e., $Y = AK^\\alpha L^{1-\\alpha}$), the marginal product of capital (MPK) can be written as:\n",
    "$$ \\frac{\\partial Y}{\\partial K} = \\alpha \\cdot \\underbrace{A{K}^\\alpha{L}^{1-\\alpha}}_{=Y}\\cdot \\frac{1}{K} = \\alpha \\frac{Y}{K} = \\alpha \\frac{Y/L}{K/L} $$\n",
    "and similarly if we are going to assume some form like $Y = AK^\\alpha$, we can write:\n",
    "$$ \\frac{\\partial Y}{\\partial K} = \\alpha \\cdot \\underbrace{AK^{\\alpha}}_{=Y} \\cdot \\frac{1}{K} = \\alpha \\frac{Y}{K} $$\n",
    "so essentially the MPK can be written as the ratio of GDP ($Y$) and capital ($K$) multiplied by the GDP elasticity w.r.t. capital ($\\alpha$).\n",
    "\n",
    "We have acquired two different estimates (one ours, one IIASA's) of $\\alpha$ from above, but we can further look at calculating $\\alpha$ for each country by fitting either a Cobb-Douglas function or a capital-only function. So there are four options for calculating a country's MPK:\n",
    "1. Use $\\alpha$ from IIASA\n",
    "2. Use $\\alpha$ from our estimation\n",
    "3. Use $\\alpha$ from fitting a Cobb-Douglas function\n",
    "4. Use $\\alpha$ from fitting a capital-only function\n",
    "\n",
    "and we can multiply the value of $\\frac{Y}{K}$ (in the year 2010) afterwards."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57a27e17",
   "metadata": {},
   "outputs": [],
   "source": [
    "MPK_init_calc_lamb = lambda x: ypk_fn.MPK_init_calc(\n",
    "    x, hist_df, k2010, [OVERALL_E, OVERALL_E_IIASA]\n",
    ")\n",
    "\n",
    "# for the inhabited areas\n",
    "mpk_calc = []\n",
    "inhabited_isos = np.setdiff1d(sset.ALL_ISOS, sset.UNINHABITED_ISOS)\n",
    "for i in tqdm(inhabited_isos):\n",
    "    lst_mpks = MPK_init_calc_lamb(i)\n",
    "    mpk_calc.append(lst_mpks)\n",
    "mpk_calc = pd.concat(mpk_calc, axis=0)\n",
    "\n",
    "# there are some cases in which the TPK and elasticities per country are not\n",
    "# found via optimization (minimization); in this case, we will clip it with\n",
    "# the minimum MPK garnered either from `mpk_our`, `mpk_iiasa`, or itself (whichever\n",
    "# is lesser yet above 0)\n",
    "for i in [\"mpk_ctry_cd\", \"mpk_ctry_co\"]:\n",
    "    cd_values = mpk_calc[[\"mpk_our\", \"mpk_iiasa\", i]].values\n",
    "    mpk_calc.loc[mpk_calc[i] == 0, i] = cd_values[cd_values > 0].min()\n",
    "\n",
    "# attaching the uninhabited areas; by default, their Y/K ratios and MPK values will\n",
    "# be set to 0 (doesn't matter too much, since their projected capitals will be 0)\n",
    "mpk_calc_uninhabited = k2010.reset_index().set_index([\"ccode\", \"ssp\", \"iam\"])\n",
    "mpk_calc_uninhabited = mpk_calc_uninhabited.loc[\n",
    "    (sset.UNINHABITED_ISOS, slice(None), slice(None)), [\"gdp\", \"capital\", \"pop\"]\n",
    "]\n",
    "for i in [\"yk\", \"mpk_our\", \"mpk_iiasa\", \"mpk_ctry_cd\", \"mpk_ctry_co\"]:\n",
    "    mpk_calc_uninhabited[i] = 0\n",
    "mpk_calc = pd.concat([mpk_calc, mpk_calc_uninhabited], axis=0).sort_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4217f3b9",
   "metadata": {},
   "source": [
    "### Using the perpetual inventory method (PIM) with the dynamic parameter equations specified in Dellink et al. (2017)\n",
    "\n",
    "The method in Dellink et al. (2017) is basically a PIM, but its parameters are dynamic (and evolving on their own) so that they approach converge to specific long-term values. Below is (with `dask` parallelization) an application of the Dellink et al. (2017) methodology using the MPKs (in 4 different methods) we have calculated above for each country.\n",
    "\n",
    "First, we load the 2010 historical values (some estimated) of capital stock into our projection dataset. Also, we calculate the by-country average depreciation rates (from PWT 10.0) and overall average (average of the by-country rates) rates (also from PWT 10.0) which are used in the PIM process. If a country is missing from the PWT 10.0 dataset, we will simply use the overall average depreciation rate for the country-specific values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca9057b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "## importing the (initial) iy ratios in 2010\n",
    "iy_org = hist_df.loc[(slice(None), [2010]), [\"iy_ratio_fit\", \"delta\"]]\n",
    "iy_org = (\n",
    "    iy_org.reset_index()\n",
    "    .rename(columns={\"delta\": \"delta_c\", \"iy_ratio_fit\": \"iy_ratio\"})\n",
    "    .drop([\"year\"], axis=1)\n",
    "    .set_index([\"ccode\"])\n",
    ")\n",
    "\n",
    "## AFG has the average delta value\n",
    "delta_overall = iy_org.loc[\"AFG\", \"delta_c\"]\n",
    "\n",
    "## merge this with the 2010 (starting point) dataset\n",
    "mpk_calc = mpk_calc.merge(iy_org, left_index=True, right_index=True, how=\"left\")\n",
    "mpk_calc[\"delta\"] = delta_overall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c5f73ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "## cluster setup\n",
    "N_CLUSTER = 20\n",
    "cluster = gateway.new_cluster(worker_image=image_name, profile=\"micro\")\n",
    "client = cluster.get_client()\n",
    "cluster.scale(N_CLUSTER)\n",
    "cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93355c2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## getting the ccodes and ccode-specific DFs necessary\n",
    "ccodes_pos_y = (\n",
    "    proj_ypk_df.loc[proj_ypk_df.gdp > 0, :].index.get_level_values(\"ccode\").unique()\n",
    ")\n",
    "ccodes_dfs = [proj_ypk_df.loc[[cc], :].copy() for cc in ccodes_pos_y]\n",
    "\n",
    "## uninhabited ones set aside\n",
    "cc_dfs_uninh = proj_ypk_df.loc[\n",
    "    ~proj_ypk_df.index.get_level_values(\"ccode\").isin(ccodes_pos_y), :\n",
    "].sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb94a190",
   "metadata": {},
   "outputs": [],
   "source": [
    "# making sure SLIIDERS functions are compatible with Dask workflow\n",
    "# run this when all the workers are available\n",
    "sliiders_dir = Path(slfile).parent\n",
    "zipf = zipfile.ZipFile(\"sliiders.zip\", \"w\", zipfile.ZIP_DEFLATED)\n",
    "for root, dirs, files in os.walk(sliiders_dir):\n",
    "    for file in files:\n",
    "        zipf.write(\n",
    "            os.path.join(root, file),\n",
    "            os.path.relpath(os.path.join(root, file), os.path.join(sliiders_dir, \"..\")),\n",
    "        )\n",
    "zipf.close()\n",
    "client.upload_file(\"sliiders.zip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa952c3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "MPK_var_cases = [\"mpk_our\", \"mpk_ctry_cd\", \"mpk_ctry_co\"] * 2\n",
    "MPK_case_len = len(MPK_var_cases)\n",
    "all_cases = []\n",
    "for i, case in enumerate(MPK_var_cases):\n",
    "    if i < (MPK_case_len // 2):\n",
    "        pim_lamb = lambda x: ypk_fn.pim_single_ctry(x, mpk_calc, OVERALL_E, case)\n",
    "    else:\n",
    "        pim_lamb = lambda x: ypk_fn.pim_single_ctry(x, mpk_calc, OVERALL_E_IIASA, case)\n",
    "    pim_dfs = client.map(pim_lamb, ccodes_dfs)\n",
    "    pim_dfs = client.gather(pim_dfs)\n",
    "    pim_dfs = pd.concat(pim_dfs, axis=0)\n",
    "    all_cases.append(pim_dfs)\n",
    "    j = i + 1\n",
    "    print(f\"Step {j}/{MPK_case_len} done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dab4482",
   "metadata": {},
   "outputs": [],
   "source": [
    "# shutting down cluster\n",
    "cluster.scale(0)\n",
    "client.close()\n",
    "cluster.close()\n",
    "cluster.shutdown()\n",
    "\n",
    "# removing the .zip file that's been uploaded to Dask\n",
    "os.remove(\"sliiders.zip\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84ea369b",
   "metadata": {},
   "source": [
    "### Checking against the Dellink et al. (2017)'s Figure 6 (capital intensity plots)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b66b707",
   "metadata": {},
   "source": [
    "We examine our 6 options as below. After examination with the graph as well as the SSE values, it seems that the case utilizing by-country MPK, **capital-only** production function, and the IIASA overall MPK are the ones that perform the best, at least with the four countries whose information are available.\n",
    "\n",
    "However, since the SSEs for the numbers are very similar between the two cases (varying only by **capital-and-labor** production versus **capital-only** production) and because capital-only one has been used previously to produce capital stock estimates, we will use estimates from `all_cases[-1]` as our main capital stock estimates and those from `all_cases[-2]` as alternative estimates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c1d3944",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_cases_sse = []\n",
    "for i in all_cases:\n",
    "    all_cases_sse.append(ypk_fn.examine_against_fig6(i))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "418aedca",
   "metadata": {},
   "source": [
    "For sanity check, we will also graph top ten and bottom cases of capital stock (in natural logarithm) for some specified SSP (SSP3 below) and some year (2100 below)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de9cdc57",
   "metadata": {},
   "outputs": [],
   "source": [
    "ypk_fn.top_bottom_10(all_cases[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46819cfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "ypk_fn.top_bottom_10(all_cases[-2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e240b14",
   "metadata": {},
   "source": [
    "## Re-organizing the dataset and exporting\n",
    "\n",
    "### Data re-organization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "042d6543",
   "metadata": {},
   "outputs": [],
   "source": [
    "# capital stock estimates\n",
    "pim_dfs_iiasa_co = all_cases[-1].copy()\n",
    "pim_dfs_iiasa_cd = all_cases[-2].copy()\n",
    "\n",
    "# creating gdppc, unit changes, and changing the name to be matched\n",
    "output_df = proj_ypk_df.rename(\n",
    "    columns={\"gdp\": \"rgdpna_19\", \"gdppc\": \"rgdpna_pc_19\"}\n",
    ").drop([\"capital\"], axis=1)\n",
    "output_df[\"pop\"] /= 1000000\n",
    "output_df[\"rgdpna_19\"] /= 1000000\n",
    "\n",
    "## attaching the capital stock estimates\n",
    "necess_cols = [\"capital_estim\", \"MPK\", \"IY\", \"KY\"]\n",
    "output_df = output_df.merge(\n",
    "    pim_dfs_iiasa_co[necess_cols].rename(columns={\"capital_estim\": \"rnna_19\"}),\n",
    "    left_index=True,\n",
    "    right_index=True,\n",
    "    how=\"left\",\n",
    ")\n",
    "output_df[\"rnna_19\"] /= 1000000\n",
    "\n",
    "alt_name = \"rnna_19_alternative\"\n",
    "output_df = output_df.merge(\n",
    "    pim_dfs_iiasa_cd[[\"capital_estim\"]].rename(columns={\"capital_estim\": alt_name}),\n",
    "    left_index=True,\n",
    "    right_index=True,\n",
    "    how=\"left\",\n",
    ")\n",
    "output_df[alt_name] /= 1000000\n",
    "\n",
    "for i in necess_cols[1:] + [alt_name, \"rnna_19\"]:\n",
    "    output_df.loc[pd.isnull(output_df[i]), i] = 0\n",
    "\n",
    "## adding the unit information and reordering\n",
    "output_df[\"gdp_capital_unit\"] = \"millions (of USD)\"\n",
    "output_df[\"gdppc_unit\"] = \"ones (of USD)\"\n",
    "output_df[\"pop_unit\"] = \"millions (of people)\"\n",
    "output_df.sort_index(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0132fe16",
   "metadata": {},
   "source": [
    "### Scale creation with respect to historical 2019 values of population and current-PPP (2019 USD) capital stock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "636201d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "## fetching the 2019 historical values\n",
    "hist_gp = (\n",
    "    hist_df.loc[(slice(None), 2019), [\"cn_19\", \"pop\"]]\n",
    "    .reset_index()\n",
    "    .drop([\"year\"], axis=1)\n",
    "    .set_index([\"ccode\"])\n",
    "    .rename(columns={\"pop\": \"pop_2019\", \"cn_19\": \"cn_19_2019\"})\n",
    ")\n",
    "\n",
    "## merge and create scales\n",
    "output_df = output_df.merge(hist_gp, left_index=True, right_index=True, how=\"left\")\n",
    "output_df[\"pop_scale\"] = output_df[\"pop\"] / output_df[\"pop_2019\"]\n",
    "output_df[\"rnna_19_scale\"] = output_df[\"rnna_19\"] / output_df[\"cn_19_2019\"]\n",
    "output_df[\"rnna_19_alternative_scale\"] = (\n",
    "    output_df[\"rnna_19_alternative\"] / output_df[\"cn_19_2019\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8298c07a",
   "metadata": {},
   "source": [
    "### Exporting: historical 2019 values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3156eb87",
   "metadata": {},
   "outputs": [],
   "source": [
    "hist2019 = hist_df.loc[\n",
    "    (slice(None), 2019),\n",
    "    [\n",
    "        \"gdp_capital_unit\",\n",
    "        \"gdppc_unit\",\n",
    "        \"pop_unit\",\n",
    "        \"cgdpo_19\",\n",
    "        \"cgdpo_pc_19\",\n",
    "        \"pop\",\n",
    "        \"cn_19\",\n",
    "    ],\n",
    "].reset_index()\n",
    "hist2019 = hist2019.drop([\"year\"], axis=1).set_index([\"ccode\"])\n",
    "hist2019.to_parquet(sset.DIR_YPK_FINAL / \"gdp_gdppc_pop_capital_hist2019.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "282846eb",
   "metadata": {},
   "source": [
    "### Exporting: projected values (2010-2100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8205448f",
   "metadata": {},
   "outputs": [],
   "source": [
    "col_ordering = [\n",
    "    \"gdp_capital_unit\",\n",
    "    \"gdppc_unit\",\n",
    "    \"pop_unit\",\n",
    "    \"rgdpna_19\",\n",
    "    \"rgdpna_pc_19\",\n",
    "    \"rnna_19\",\n",
    "    \"rnna_19_scale\",\n",
    "    \"rnna_19_alternative\",\n",
    "    \"rnna_19_alternative_scale\",\n",
    "    \"cn_19_2019\",\n",
    "    \"pop\",\n",
    "    \"pop_scale\",\n",
    "    \"pop_2019\",\n",
    "    \"MPK\",\n",
    "    \"IY\",\n",
    "    \"KY\",\n",
    "]\n",
    "\n",
    "## filling in the nan's with 0, for uninhabited areas\n",
    "output_df = output_df[col_ordering].copy().sort_index()\n",
    "for i in [\"rgdpna_pc_19\", \"rnna_19_scale\", \"rnna_19_alternative_scale\", \"pop_scale\"]:\n",
    "    output_df.loc[pd.isnull(output_df[i]), i] = 0\n",
    "\n",
    "output_df.to_parquet(\n",
    "    sset.DIR_YPK_FINAL / \"gdp_gdppc_pop_capital_proj_2010_2100.parquet\"\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
